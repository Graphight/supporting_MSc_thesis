{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59923c8b-4332-4e52-8edd-ed881e9b08c2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81501234-f67d-4bc1-b895-66d41e98c31c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import geopandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bamboolib as bam\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import lightgbm as lgb\n",
    "import plotly.express as px\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.animation as anim \n",
    "import plotly.graph_objects as go \n",
    "\n",
    "from time import time\n",
    "from multiprocessing import Pool\n",
    "from os import makedirs\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from json import dumps, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb740fa-027f-4304-bfff-a245c6d0b151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044d87c-5f04-4be3-8e20-8798403b09c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f212a661-eace-4e1d-b617-c2e98bd99d5d",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e643085-91ae-4cb5-a68f-cea9d0e51113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR_HAPPI = \"/Volumes/T7/ExtremeWeather/Data_WeatherAtHome/HAPPI\"\n",
    "\n",
    "DIR_VCSN = \"/Volumes/T7/ExtremeWeather/Data_VCSN\"\n",
    "\n",
    "DIR_PLOTS = \"../Plots_Paper\"\n",
    "\n",
    "DIR_PLOTS_THESIS = \"../Plots_Thesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a11a6d-5975-48d1-81af-5946a11b1641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a8506-5e2a-4b76-b78b-ee9c91c6b395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d5557b3-8de1-4ce7-89e8-f58c2798f447",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part 1 - Determine how many days are required to reach 25% and 75% total rainfall in the Current-decade (ALL) HAPPI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a63f7-cd98-4ea8-bfdc-e811e0ff0a02",
   "metadata": {},
   "source": [
    "Brief from Luke:\n",
    "\n",
    "Find the value, N, such that it’s “N wettest days required to reach 25% of climatological annual rainfall” in the current climate/ALL runs, separately for each grid cell. And then repeat to find X such that it’s “X driest days required to also reach 25% of climatological annual rainfall”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8f99f-e0d1-4f60-bac5-de85005ae936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4861a3e6-a7b7-4752-9eb9-41239c70ca72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dbf68-2baf-497f-a2c2-1b30bed1b869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_n_days_to_reach_yearly_precip_percent(\n",
    "    df: pd.DataFrame,\n",
    "    grid_cell_dict: dict(),\n",
    "    target_wet_percent: float,\n",
    "    target_dry_percent: float,\n",
    "    target_col: str,\n",
    "    model_name: str,\n",
    "    region_name: str\n",
    ") -> (list, list):\n",
    "    for grid_cell in df[\"grid_cell\"].unique():\n",
    "        df_cell = df.loc[df[\"grid_cell\"] == grid_cell]\n",
    "        df_cell = df_cell.sort_values([target_col], ascending=False).reset_index(drop=True)\n",
    "\n",
    "        total_target = df_cell[target_col].sum()\n",
    "\n",
    "        df_cell[f\"cumulative_{target_col}\"] = df_cell[target_col].cumsum()\n",
    "        df_cell[f\"cumulative_{target_col}_percent\"] = df_cell[f\"cumulative_{target_col}\"] / total_target\n",
    "\n",
    "        df_cell[\"n_wet\"] = df_cell[f\"cumulative_{target_col}_percent\"] >= target_wet_percent\n",
    "        df_cell[\"n_dry\"] = df_cell[f\"cumulative_{target_col}_percent\"] >= target_dry_percent\n",
    "        \n",
    "        grid_cell_dict[\"region\"].append(region_name)\n",
    "        grid_cell_dict[\"grid_cell\"].append(grid_cell)\n",
    "        grid_cell_dict[\"model\"].append(model_name)\n",
    "        grid_cell_dict[\"wet\"].append(int(df_cell[df_cell[\"n_wet\"]].index.min()))\n",
    "        grid_cell_dict[\"dry\"].append(int(df_cell.shape[0] - df_cell[df_cell[\"n_dry\"]].index.min()))\n",
    "\n",
    "\n",
    "def generate_fixed_precip_percent_chunk_wah(file: str) -> None:\n",
    "    try:\n",
    "        region = re.findall(r\"region=(.*?)/\", file)[0]\n",
    "        source = re.findall(r\"sim=(.*?)/\", file)[0]\n",
    "        year = \"\" if \"year\" not in file else re.findall(r\"year=(.*?)/\", file)[0]\n",
    "\n",
    "        grid_cell_dict = {\n",
    "            \"region\": [],\n",
    "            \"grid_cell\": [],\n",
    "            \"model\": [],\n",
    "            \"wet\": [],\n",
    "            \"dry\": []\n",
    "        }\n",
    "\n",
    "        target_wet_percent = 0.25\n",
    "        target_dry_percent = 0.75\n",
    "\n",
    "        target_col = \"precip_mm\"\n",
    "        input_cols = [\n",
    "            \"grid_cell\",\n",
    "            target_col\n",
    "        ]\n",
    "\n",
    "        for model_dir in sorted(glob(f\"{file}model_tag=*/\")):\n",
    "            model_name = re.findall(r\"model_tag=(.*?)/\", model_dir)[0]\n",
    "            \n",
    "            determine_n_days_to_reach_yearly_precip_percent(\n",
    "                df=pd.read_parquet(model_dir, engine=\"pyarrow\", columns=input_cols),\n",
    "                grid_cell_dict=grid_cell_dict,\n",
    "                target_wet_percent=target_wet_percent,\n",
    "                target_dry_percent=target_dry_percent,\n",
    "                target_col=target_col,\n",
    "                model_name=model_name,\n",
    "                region_name=region\n",
    "            )\n",
    "        \n",
    "        parent_dir = f\"{DATA_DIR_SIM_FIXED_PRECIP_OUTPUT}/year={year}/source={source}\"\n",
    "        makedirs(parent_dir, exist_ok=True)\n",
    "        file_path = f\"{parent_dir}/{region}.parquet\"\n",
    "        df = pd.DataFrame(data=grid_cell_dict)\n",
    "        df.to_parquet(file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Encountered an error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404255c-23eb-46dd-9a01-d70c96ba0b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_fixed_precip_percent_wah(sim_type: str, files: [str]) -> None:\n",
    "    print(f\"\\nFor {sim_type} forcing I found {len(files):,} files, opening the pool [ size: {POOL_SIZE} ]\")\n",
    "\n",
    "    time_start = time()\n",
    "    \n",
    "    # ===========================================\n",
    "    # Pooling is broken in notebooks, I can't be bothered figuring this out so just run it from an IDE or terminal (it will take around 1 minute)\n",
    "    # pool = Pool(processes=POOL_SIZE)\n",
    "    # for _ in tqdm(pool.imap_unordered(generate_fixed_precip_percent_chunk_wah, files), total=len(files)):\n",
    "    #     pass    # We just need some dummy statement for the progress bar\n",
    "    # pool.close()\n",
    "    \n",
    "    # ============================================\n",
    "    # Slow single threaded version\n",
    "    # If you really want to run in this notebook then do this one (it will take around 10 minutes)\n",
    "    for file in tqdm(files, desc=\"Slow single threaded loop\"):\n",
    "        generate_fixed_precip_percent_chunk_wah(file)\n",
    "\n",
    "    print(f\"Finished processing all {len(files):,} files. The pool has been closed.\")\n",
    "    print(f\"The whole thing took: {(time() - time_start):,.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ea540-a690-412c-a5d3-2358d02058e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07c88a5-2501-4747-a199-87ca8d7a05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "POOL_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e501ae-75b4-4f25-8450-6338d4aabcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR_SIM_INPUT = f\"{DIR_HAPPI}/Processed/\"\n",
    "DATA_DIR_SIM_FIXED_PRECIP_OUTPUT = f\"{DIR_HAPPI}/RVI/Chunks_Fixed_PrecipPercent/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c839916-e569-441e-97d3-c31d63d3340b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_fixed_precip_percent_wah(\"ALL\", sorted(glob(f\"{DATA_DIR_SIM_INPUT}/year=*/region=*/sim=ALL/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7978d447-0d7d-4f97-ab8e-00672b8318d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0f22a7-c035-41a5-b0ec-ecfb2f7eac49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46283237-b8aa-4a33-a52c-e484b0db1f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72518d7-151b-4f3c-ac54-f07cc5ac68eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf27c2-6a50-41ba-9342-4521ad2329d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e5ca48-bd61-4c9e-aca7-deab23154ccd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part 2 - Determine how much rain falls within fixed number of days for each grid cell of each model of each year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620ccd4-a033-4ad0-9249-e08ec422af87",
   "metadata": {},
   "source": [
    "Once you’ve identified N and X for each gridcell, keep those numbers fixed from now on. And then search through each ensemble member to just calculate the total millimetres of rain which fell on the same fixed N wettest days and X driest days for each model year. That way, you’ll produce a distribution of answers (one model year each), with the units being how many mm of rain fell on the N wettest days and X driest days, at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638ea86-683c-4f43-9515-95f9194df541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ = df.loc[df[\"grid_cell\"] == \"-35.995018_174.70364\"]\n",
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b523443-6d62-4570-a1a1-d00efff4565e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Figure out what good N and X values are for the various grid_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc816dd4-a78b-443f-b4bd-616adb02fb5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_PrecipPercent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4757b2f3-8097-4f06-a287-78729ed7ebda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"region\",\n",
    "    \"grid_cell\",\n",
    "    # \"year\",\n",
    "    \"source\"\n",
    "]\n",
    "\n",
    "target_cols = [\n",
    "    \"wet\",\n",
    "    \"dry\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c9274-2777-4d22-8fad-ff335a2e79e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_grouped = df[group_cols + target_cols].groupby(by=group_cols).mean()\n",
    "\n",
    "df_grouped = df_grouped.dropna().reset_index().round()\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516734c2-2e2e-4323-95b9-9bdf76d77a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb7195-2a8b-4215-8642-3a67679864e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_cell_map = dict()\n",
    "\n",
    "for row in df_grouped.loc[df_grouped[\"source\"] == \"ALL\"].copy()[[\"grid_cell\", \"wet\", \"dry\"]].values:\n",
    "    grid_cell_map[row[0]] = {\n",
    "        \"wet\": row[1],\n",
    "        \"dry\": row[2]\n",
    "    }\n",
    "    \n",
    "file_path = f\"{DIR_HAPPI}/RVI/fixed_precip_grid_cell_map.json\"\n",
    "with open(file_path, \"w\") as f_out:\n",
    "    f_out.write(dumps(grid_cell_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04085437-9279-4c5f-b409-25305ed04fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faec5305-0571-4ff8-9954-009aacb08f31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca7c6c-95bf-4853-a7d4-28a95154eeb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_total_precip_for_each_grid_cell_on_specific_days(\n",
    "    df: pd.DataFrame,\n",
    "    grid_cell_dict: dict,\n",
    "    grid_cell_day_map: dict,\n",
    "    target_col: str,\n",
    "    model_name: str,\n",
    "    region_name: str\n",
    ") -> (list, list):\n",
    "    for grid_cell in df[\"grid_cell\"].unique():\n",
    "        df_cell = df.loc[df[\"grid_cell\"] == grid_cell]\n",
    "        df_cell = df_cell.sort_values([target_col], ascending=False).reset_index(drop=True)\n",
    "        \n",
    "        target_wet_days = int(grid_cell_day_map[grid_cell][\"wet\"])\n",
    "        target_dry_days = df_cell.shape[0] - int(grid_cell_day_map[grid_cell][\"dry\"])\n",
    "        \n",
    "        total_precip_wet_days = df_cell.iloc[0:target_wet_days][target_col].sum()\n",
    "        total_precip_dry_days = df_cell.iloc[target_dry_days:][target_col].sum()\n",
    "        \n",
    "        grid_cell_dict[\"region\"].append(region_name)\n",
    "        grid_cell_dict[\"grid_cell\"].append(grid_cell)\n",
    "        grid_cell_dict[\"model\"].append(model_name)\n",
    "        grid_cell_dict[\"total_precip_wet_days\"].append(total_precip_wet_days)\n",
    "        grid_cell_dict[\"total_precip_dry_days\"].append(total_precip_dry_days)\n",
    "\n",
    "\n",
    "def generate_fixed_days_chunk_wah(file: str) -> None:\n",
    "    try:\n",
    "        region = re.findall(r\"region=(.*?)/\", file)[0]\n",
    "        source = re.findall(r\"sim=(.*?)/\", file)[0]\n",
    "        year = \"\" if \"year\" not in file else re.findall(r\"year=(.*?)/\", file)[0]\n",
    "\n",
    "        grid_cell_dict = {\n",
    "            \"region\": [],\n",
    "            \"grid_cell\": [],\n",
    "            \"model\": [],\n",
    "            \"total_precip_wet_days\": [],\n",
    "            \"total_precip_dry_days\": []\n",
    "        }\n",
    "        \n",
    "        grid_cell_day_map = load(open(f\"{DIR_HAPPI}/RVI/fixed_precip_grid_cell_map.json\"))\n",
    "\n",
    "        target_col = \"precip_mm\"\n",
    "        input_cols = [\n",
    "            \"grid_cell\",\n",
    "            target_col\n",
    "        ]\n",
    "\n",
    "        for model_dir in sorted(glob(f\"{file}model_tag=*/\")):\n",
    "            model_name = re.findall(r\"model_tag=(.*?)/\", model_dir)[0]\n",
    "            \n",
    "            determine_total_precip_for_each_grid_cell_on_specific_days(\n",
    "                df=pd.read_parquet(model_dir, engine=\"pyarrow\", columns=input_cols),\n",
    "                grid_cell_dict=grid_cell_dict,\n",
    "                grid_cell_day_map=grid_cell_day_map,\n",
    "                target_col=target_col,\n",
    "                model_name=model_name,\n",
    "                region_name=region\n",
    "            )\n",
    "        \n",
    "        parent_dir = f\"{DATA_DIR_SIM_FIXED_DAYS_OUTPUT}/year={year}/source={source}\"\n",
    "        makedirs(parent_dir, exist_ok=True)\n",
    "        file_path = f\"{parent_dir}/{region}.parquet\"\n",
    "        df = pd.DataFrame(data=grid_cell_dict)\n",
    "        df.to_parquet(file_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Encountered an error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d139c2-6d95-4ce9-9997-fbe331c28b60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_fixed_days_wah(sim_type: str, files: [str]) -> None:\n",
    "    print(f\"\\nFor {sim_type} forcing I found {len(files):,} files, opening the pool [ size: {POOL_SIZE} ]\")\n",
    "\n",
    "    time_start = time()\n",
    "    \n",
    "    # ===========================================\n",
    "    # Pooling is broken in notebooks, I can't be bothered figuring this out so just run it from an IDE or terminal (it will take around 1 minute)\n",
    "    # pool = Pool(processes=POOL_SIZE)\n",
    "    # for _ in tqdm(pool.imap_unordered(generate_fixed_days_chunk_wah, files), total=len(files)):\n",
    "    #     pass    # We just need some dummy statement for the progress bar\n",
    "    # pool.close()\n",
    "    \n",
    "    # ============================================\n",
    "    # Slow single threaded version\n",
    "    # If you really want to run in this notebook then do this one (it will take around 10 minutes)\n",
    "    for file in tqdm(files, desc=\"Slow single threaded loop\"):\n",
    "        generate_fixed_days_chunk_wah(file)\n",
    "\n",
    "    print(f\"Finished processing all {len(files):,} files. The pool has been closed.\")\n",
    "    print(f\"The whole thing took: {(time() - time_start):,.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3baf9-ad32-494d-a50b-9cb0d95865f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR_SIM_INPUT = f\"{DIR_HAPPI}/Processed/\"\n",
    "DATA_DIR_SIM_FIXED_DAYS_OUTPUT = f\"{DIR_HAPPI}/RVI/Chunks_Fixed_Days/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131df212-8f2d-46a1-a91b-7a00019a87cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_fixed_days_wah(\"ALL\", sorted(glob(f\"{DATA_DIR_SIM_INPUT}/year=*/region=*/sim=ALL/\")))\n",
    "process_fixed_days_wah(\"NAT\", sorted(glob(f\"{DATA_DIR_SIM_INPUT}/year=*/region=*/sim=NAT/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce2df4-d5f0-4974-8e1f-aae65357ca2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eaeeaa-f41b-4de2-be9c-3d33cf89dabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e5b0b3-c8a8-4415-9961-b1debccd095e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part 3 - Repeat part 2 for the 3-DEG (HOT) HAPPI data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a0f902-6a7a-497f-97cf-db40a943670a",
   "metadata": {},
   "source": [
    "Repeat for your other warmer-world experiment (for the paper, this will be the 3 degree HAPPI simulations), again keeping N and X fixed as the values defined based on the current climate/ALL experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5697417-7a6a-4d63-aba2-a28bfde8a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_SIM_INPUT = f\"{DIR_HAPPI}/Processed/\"\n",
    "\n",
    "DATA_DIR_SIM_FIXED_DAYS_OUTPUT = f\"{DIR_HAPPI}/RVI/Chunks_Fixed_Days\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b42fe-7341-4779-b74b-74b28d246ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_fixed_days_wah(\"HOT\", sorted(glob(f\"{DATA_DIR_SIM_INPUT}/year=*/region=*/sim=HOT/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe7839-d76f-4075-9ade-493e4ec83260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6653bdbe-3143-4bf7-b734-3ad9ae254d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3555a95-b6b6-4fb9-8833-f304891b7d82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part 4 - Produce ensemble maps showing differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f288ee-05dd-4dcf-a815-05e2cbdb7493",
   "metadata": {},
   "source": [
    "Now you have two distributions (one current climate, one warmer world) of “mm which fell on the N wettest days of the year”, and then another two distributions (one current climate, one warmer world) of “mm which fell on X driest days of the year”. \n",
    "\n",
    "Then you can produce a map of the ensemble median change (percent difference) in rain which falls on the N wettest days of the year, and on the X driest days of the year – this is what we already have (see attached figures). But what we also want to do is produce equivalent maps but comparing the wetter ensemble members of each experiment. \n",
    "\n",
    "So we want to look at the 95th percentile ensemble member answer in the current climate and compare with the 95th percentile ensemble member answer in the future climate. So rather than “an additional 8% of rain falls in the wettest N days of the year”, now it might be “an additional 12% of rain falls in the wettest N days of the year when it’s an extreme wet year”. Or something. And then vice-versa, look to compare the 5th percentile of ensemble members in the future against the 5th percentile of ensemble members in current climate for the “mm falling on X driest days” metric, too. Example for one grid cell in Northland is attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71032f8-6b7f-460c-b107-5eda4a3d3576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7ccb9-3937-422d-9b7f-a3d23e98cf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43cc8086-ba16-4970-8700-012f36a8c0ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab9bf3-b306-4ee0-9061-225d4544df18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel = [(\"region\", \"!=\", \"Area Outside Region\")]\n",
    "\n",
    "df = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_Days/\", filters=sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e3a195-94df-4042-a39c-6fdba22a921a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ALL = df.loc[df[\"source\"] == \"ALL\"].copy().reset_index(drop=True)\n",
    "df_HOT = df.loc[df[\"source\"] == \"HOT\"].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76a699-cea8-41d2-851f-67060a864eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Attach days required to datasets\n",
    "with open(f\"{DIR_HAPPI}/RVI/fixed_precip_grid_cell_map.json\") as json_file:\n",
    "    fixed_precip_grid_cell_map = load(json_file)\n",
    "    \n",
    "fixed_precip_grid_cell_map_wet = {}\n",
    "fixed_precip_grid_cell_map_dry = {}\n",
    "\n",
    "for key, value in fixed_precip_grid_cell_map.items():\n",
    "    fixed_precip_grid_cell_map_wet[key] = int(value[\"wet\"])\n",
    "    fixed_precip_grid_cell_map_dry[key] = int(value[\"dry\"])\n",
    "\n",
    "df_ALL[\"days_wet\"] = df_ALL[\"grid_cell\"].map(fixed_precip_grid_cell_map_wet)\n",
    "df_ALL[\"days_dry\"] = df_ALL[\"grid_cell\"].map(fixed_precip_grid_cell_map_dry)\n",
    "df_HOT[\"days_wet\"] = df_HOT[\"grid_cell\"].map(fixed_precip_grid_cell_map_wet)\n",
    "df_HOT[\"days_dry\"] = df_HOT[\"grid_cell\"].map(fixed_precip_grid_cell_map_dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba7486-7e3d-4eed-9f06-be1e27c7d045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc22a1-91e4-437b-8fea-eb7c054020b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10a8e4eb-5fa3-4f86-acb0-84efe1b44bb7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Recreate the median difference maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac391d3a-d600-4f5a-bcab-5a6a49a21d67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649b548-e2e6-498b-9001-2868f2ed4dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"grid_cell\",\n",
    "]\n",
    "\n",
    "target_cols = [\n",
    "    \"total_precip_wet_days\",\n",
    "    \"total_precip_dry_days\",\n",
    "]\n",
    "\n",
    "df_ALL_grouped = df_ALL[group_cols + target_cols].groupby(by=group_cols).median().reset_index()\n",
    "df_HOT_grouped = df_HOT[group_cols + target_cols].groupby(by=group_cols).median().reset_index()\n",
    "\n",
    "df_merged = df_HOT_grouped.merge(\n",
    "    right=df_ALL_grouped,\n",
    "    how=\"left\",\n",
    "    on=\"grid_cell\",\n",
    "    suffixes=[\"_HOT\", \"_ALL\"]\n",
    ")\n",
    "\n",
    "df_merged[\"total_precip_wet_days_diff\"] = df_merged[\"total_precip_wet_days_HOT\"] / df_merged[\"total_precip_wet_days_ALL\"]\n",
    "df_merged[\"total_precip_dry_days_diff\"] = df_merged[\"total_precip_dry_days_HOT\"] / df_merged[\"total_precip_dry_days_ALL\"]\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_merged[\"grid_cell\"].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"latitude\", \"longitude\"]\n",
    "df_merged = pd.merge(df_merged, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "df_merged[\"longitude\"] = df_merged[\"longitude\"].astype(float)\n",
    "df_merged[\"latitude\"] = df_merged[\"latitude\"].astype(float)\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81bbac-565f-4f0a-b933-41e4180435ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_CRS = \"EPSG:4326\"\n",
    "\n",
    "df_merged = df_merged.set_geometry(\n",
    "    geopandas.points_from_xy(\n",
    "            x=df_merged[\"longitude\"], \n",
    "            y=df_merged[\"latitude\"], \n",
    "            crs=DEFAULT_CRS\n",
    "    )\n",
    ")\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761dabd3-9d13-44b8-9f3e-38f961ab73fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758e9dd-c7a0-41d5-a302-01271ecb13ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df_merged, \n",
    "    x='longitude', \n",
    "    y='latitude', \n",
    "    color='total_precip_wet_days_diff', \n",
    "    symbol_sequence=['circle'], \n",
    "    height=800, \n",
    "    width=800,\n",
    "    template=\"plotly_white\",\n",
    "    color_continuous_scale=\"GnBu\",\n",
    "    # range_color=(100, 130)\n",
    ")\n",
    "\n",
    "fig.update_traces(marker={'size': 19})\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae346b96-f520-4a2c-9b3a-7198013cf361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df_merged, \n",
    "    x='longitude', \n",
    "    y='latitude', \n",
    "    color='total_precip_dry_days_diff', \n",
    "    # symbol_sequence=['diamond'], \n",
    "    symbol_sequence=['circle'], \n",
    "    height=800, \n",
    "    width=800,\n",
    "    template=\"plotly_white\",\n",
    "    color_continuous_scale=\"OrRd\",\n",
    "    # range_color=(100, 130)\n",
    ")\n",
    "\n",
    "fig.update_traces(marker={'size': 19})\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749bdbd-0d36-4abb-94e1-82dc877c2997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd47255-fa6f-438a-81dd-959657dadfb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002966e7-2c66-493f-ab7b-d07d0355104d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278bd67-f6aa-47ec-8fe5-3f5503e413d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "# Iterate over each grid cell\n",
    "for grid_cell in tqdm(df_ALL[\"grid_cell\"].unique(), desc=\"Grid_cell Loop\"):\n",
    "    # Filter to that grid cell data\n",
    "    df_temp_ALL = df_ALL.loc[df_ALL[\"grid_cell\"] == grid_cell].copy()\n",
    "    df_temp_HOT = df_HOT.loc[df_HOT[\"grid_cell\"] == grid_cell].copy()\n",
    "    \n",
    "    # Determine wet and dry quantiles\n",
    "    df_temp_ALL[\"wet_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_wet_days\"], q=100, labels=np.arange(1, 101, 1))\n",
    "    df_temp_ALL[\"dry_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_dry_days\"], q=100, labels=np.arange(1, 101, 1))\n",
    "    df_temp_HOT[\"wet_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_wet_days\"], q=100, labels=np.arange(1, 101, 1))\n",
    "    df_temp_HOT[\"dry_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_dry_days\"], q=100, labels=np.arange(1, 101, 1))\n",
    "    \n",
    "    # Change the quantile cols to strings then integers as they start as objects\n",
    "    df_temp_ALL[\"wet_quantile\"] = df_temp_ALL[\"wet_quantile\"].astype(str).astype(int)\n",
    "    df_temp_ALL[\"dry_quantile\"] = df_temp_ALL[\"dry_quantile\"].astype(str).astype(int)\n",
    "    df_temp_HOT[\"wet_quantile\"] = df_temp_HOT[\"wet_quantile\"].astype(str).astype(int)\n",
    "    df_temp_HOT[\"dry_quantile\"] = df_temp_HOT[\"dry_quantile\"].astype(str).astype(int)\n",
    "\n",
    "    # ==================================================================================================================================\n",
    "    # I am quite tired and seem to have broken the \"merge\" function. I can't be bothered fixing it so this is a fast workaround\n",
    "    \n",
    "    # Group by the quantiles taking the median of each quantile, this \"bins them\"\n",
    "    group_cols = [\n",
    "        \"grid_cell\",\n",
    "        \"days_wet\",\n",
    "        \"days_dry\",\n",
    "    ]\n",
    "    wet_cols = [\n",
    "        \"total_precip_wet_days\",\n",
    "        \"wet_quantile\",\n",
    "    ]\n",
    "    dry_cols = [\n",
    "        \"total_precip_dry_days\",\n",
    "        \"dry_quantile\"\n",
    "    ]\n",
    "    df_ALL_wet = df_temp_ALL[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "    df_ALL_dry = df_temp_ALL[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "    df_ALL_wet[\"total_precip_dry_days\"] = df_ALL_dry[\"total_precip_dry_days\"]\n",
    "    df_ALL_wet[\"dry_quantile\"] = df_ALL_dry[\"dry_quantile\"]\n",
    "    df_HOT_wet = df_temp_HOT[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "    df_HOT_dry = df_temp_HOT[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "    df_HOT_wet[\"total_precip_dry_days\"] = df_HOT_dry[\"total_precip_dry_days\"]\n",
    "    df_HOT_wet[\"dry_quantile\"] = df_HOT_dry[\"dry_quantile\"]\n",
    "\n",
    "    # Merge them back into one\n",
    "    df_merged = df_ALL_wet[group_cols]\n",
    "    for col in [\n",
    "        \"total_precip_wet_days\",\n",
    "        \"total_precip_dry_days\",\n",
    "        \"wet_quantile\",\n",
    "        \"dry_quantile\",\n",
    "    ]:\n",
    "        if \"wet\" in col:\n",
    "            df_merged[f\"{col}_HOT\"] = df_HOT_wet[col]\n",
    "            df_merged[f\"{col}_ALL\"] = df_ALL_wet[col]\n",
    "        else:\n",
    "            df_merged[f\"{col}_HOT\"] = df_HOT_dry[col]\n",
    "            df_merged[f\"{col}_ALL\"] = df_ALL_dry[col]\n",
    "    \n",
    "    # ==================================================================================================================================\n",
    "    \n",
    "    # Determine total_precip_xxx_days_fraction here to save time\n",
    "    df_merged[\"total_precip_wet_days_fraction\"] = df_merged[\"total_precip_wet_days_HOT\"] / df_merged[\"total_precip_wet_days_ALL\"]\n",
    "    df_merged[\"total_precip_dry_days_fraction\"] = df_merged[\"total_precip_dry_days_HOT\"] / df_merged[\"total_precip_dry_days_ALL\"]\n",
    "    \n",
    "    # Pull out the lon and lat values\n",
    "    grid_cell_parts = grid_cell.split(\"_\")\n",
    "    lon = grid_cell_parts[0]\n",
    "    lat = grid_cell_parts[1]\n",
    "    df_merged[\"longitude\"] = lon\n",
    "    df_merged[\"latitude\"] = lat\n",
    "    \n",
    "    # Append this to the big list\n",
    "    dfs.append(df_merged)\n",
    "\n",
    "# Concat all the dfs into one giga-one\n",
    "df_merged = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bcb87-5edd-4d7c-a951-ccc095117ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebf411-1b70-4f1e-a0c1-14c5d1a25984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b33ca-1f8b-4757-9622-0a2599233436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c73cd1-3438-423c-ae9e-f4976471e948",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Automated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be73049-0f8b-4e44-9b3e-70751cb777d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_quantiles_for_data(df_ALL, df_HOT, num_quantiles=100):\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each grid cell\n",
    "    for grid_cell in tqdm(df_ALL[\"grid_cell\"].unique(), desc=\"Grid_cell Loop\"):\n",
    "        # Filter to that grid cell data\n",
    "        df_temp_ALL = df_ALL.loc[df_ALL[\"grid_cell\"] == grid_cell].copy()\n",
    "        df_temp_HOT = df_HOT.loc[df_HOT[\"grid_cell\"] == grid_cell].copy()\n",
    "\n",
    "        # Determine wet and dry quantiles\n",
    "        df_temp_ALL[\"wet_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_ALL[\"dry_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_dry_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"wet_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"dry_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_dry_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "\n",
    "        # Change the quantile cols to strings then integers as they start as objects\n",
    "        df_temp_ALL[\"wet_quantile\"] = df_temp_ALL[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_ALL[\"dry_quantile\"] = df_temp_ALL[\"dry_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"wet_quantile\"] = df_temp_HOT[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"dry_quantile\"] = df_temp_HOT[\"dry_quantile\"].astype(str).astype(int)\n",
    "\n",
    "        # ==================================================================================================================================\n",
    "        # I am quite tired and seem to have broken the \"merge\" function. I can't be bothered fixing it so this is a fast workaround\n",
    "\n",
    "        # Group by the quantiles taking the median of each quantile, this \"bins them\"\n",
    "        group_cols = [\n",
    "            \"grid_cell\",\n",
    "            \"days_wet\",\n",
    "            \"days_dry\",\n",
    "        ]\n",
    "        wet_cols = [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"wet_quantile\",\n",
    "        ]\n",
    "        dry_cols = [\n",
    "            \"total_precip_dry_days\",\n",
    "            \"dry_quantile\"\n",
    "        ]\n",
    "        df_ALL_wet = df_temp_ALL[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_ALL_dry = df_temp_ALL[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "        df_ALL_wet[\"total_precip_dry_days\"] = df_ALL_dry[\"total_precip_dry_days\"]\n",
    "        df_ALL_wet[\"dry_quantile\"] = df_ALL_dry[\"dry_quantile\"]\n",
    "        df_HOT_wet = df_temp_HOT[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_HOT_dry = df_temp_HOT[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "        df_HOT_wet[\"total_precip_dry_days\"] = df_HOT_dry[\"total_precip_dry_days\"]\n",
    "        df_HOT_wet[\"dry_quantile\"] = df_HOT_dry[\"dry_quantile\"]\n",
    "\n",
    "        # Merge them back into one\n",
    "        df_merged = df_ALL_wet[group_cols]\n",
    "        for col in [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"total_precip_dry_days\",\n",
    "            \"wet_quantile\",\n",
    "            \"dry_quantile\",\n",
    "        ]:\n",
    "            if \"wet\" in col:\n",
    "                df_merged[f\"{col}_HOT\"] = df_HOT_wet[col]\n",
    "                df_merged[f\"{col}_ALL\"] = df_ALL_wet[col]\n",
    "            else:\n",
    "                df_merged[f\"{col}_HOT\"] = df_HOT_dry[col]\n",
    "                df_merged[f\"{col}_ALL\"] = df_ALL_dry[col]\n",
    "\n",
    "        # ==================================================================================================================================\n",
    "\n",
    "        # Determine total_precip_xxx_days_fraction here to save time\n",
    "        df_merged[\"total_precip_wet_days_fraction\"] = (df_merged[\"total_precip_wet_days_HOT\"] / df_merged[\"total_precip_wet_days_ALL\"]).astype(float).round(3)\n",
    "        df_merged[\"total_precip_dry_days_fraction\"] = (df_merged[\"total_precip_dry_days_HOT\"] / df_merged[\"total_precip_dry_days_ALL\"]).astype(float).round(3)\n",
    "        \n",
    "        \n",
    "        # Pull out the lon and lat values\n",
    "        grid_cell_parts = grid_cell.split(\"_\")\n",
    "        lat = float(grid_cell_parts[0])\n",
    "        lon = float(grid_cell_parts[1])\n",
    "        df_merged[\"longitude\"] = lon\n",
    "        df_merged[\"latitude\"] = lat\n",
    "\n",
    "        # Append this to the big list\n",
    "        dfs.append(df_merged)\n",
    "\n",
    "    # Concat all the dfs into one giga-one\n",
    "    return pd.concat(dfs)\n",
    "    \n",
    "\n",
    "\n",
    "def plot_difference_map_quantile(df_merged, target_quantile, target_scenario):\n",
    "    colour_map = {\n",
    "        \"Dry End\": \"OrRd\",\n",
    "        \"Wet End\": \"GnBu\"\n",
    "    }\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_merged, \n",
    "        x='longitude', \n",
    "        y='latitude', \n",
    "        color=f\"{target_scenario}\", \n",
    "        symbol_sequence=[\"circle\"], \n",
    "        height=900, \n",
    "        width=800,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_map[target_scenario],\n",
    "        range_color=(0.75, 1.25)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Change in Expected Precipitation (HOT / ALL) {target_scenario} [ {target_quantile}th bin ]\",\n",
    "        coloraxis_colorbar=dict(title=\"\")\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title=\"Longitude\", visible=True)\n",
    "    fig.update_yaxes(title=\"Latitude\", visible=True)\n",
    "    \n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461f712-dace-42a7-a328-39a4585189e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = determine_quantiles_for_data(df_ALL, df_HOT, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea6d32-7fa8-41ae-a982-3f13e784393f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.to_parquet(f\"{DIR_HAPPI}/RVI/fixed_day_grid_cell_quantiles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f8e42-c147-4b9c-bed0-b8602ae0d65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9acec-81f5-4a8b-b7b8-99251e9941e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.rename(\n",
    "    columns={\n",
    "        \"total_precip_wet_days_fraction\": \"Wet End\", \n",
    "        \"total_precip_dry_days_fraction\": \"Dry End\"\n",
    "    }, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ad654-687b-49f8-9507-c1f1386fede3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d642ba0-0de7-4c68-8c58-e3f3943c4423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = 50\n",
    "df_quantile = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == target_quantile].copy()\n",
    "\n",
    "fig_wet = plot_difference_map_quantile(df_quantile, target_quantile, \"Wet End\")\n",
    "fig_dry = plot_difference_map_quantile(df_quantile, target_quantile, \"Dry End\")\n",
    "\n",
    "fig_wet.show()\n",
    "fig_dry.show()\n",
    "\n",
    "fig_wet.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.html\")\n",
    "fig_dry.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.html\")\n",
    "\n",
    "fig_wet.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.png\", format=\"png\", scale=2)\n",
    "fig_dry.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecdd2c-8f47-4e0f-93f0-5ce770dc3833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = 10\n",
    "df_quantile = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == target_quantile].copy()\n",
    "\n",
    "fig_wet = plot_difference_map_quantile(df_quantile, target_quantile, \"Wet End\")\n",
    "fig_dry = plot_difference_map_quantile(df_quantile, target_quantile, \"Dry End\")\n",
    "\n",
    "fig_wet.show()\n",
    "fig_dry.show()\n",
    "\n",
    "fig_wet.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.html\")\n",
    "fig_dry.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.html\")\n",
    "\n",
    "fig_wet.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.png\", format=\"png\", scale=2)\n",
    "fig_dry.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe4bc7-a639-444c-b9d4-eedd7d9fcf62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = 90\n",
    "df_quantile = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == target_quantile].copy()\n",
    "\n",
    "fig_wet = plot_difference_map_quantile(df_quantile, target_quantile, \"Wet End\")\n",
    "fig_dry = plot_difference_map_quantile(df_quantile, target_quantile, \"Dry End\")\n",
    "\n",
    "fig_wet.show()\n",
    "fig_dry.show()\n",
    "\n",
    "fig_wet.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.html\")\n",
    "fig_dry.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.html\")\n",
    "\n",
    "fig_wet.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.png\", format=\"png\", scale=2)\n",
    "fig_dry.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9ecce-6885-4436-bf96-ebcf3c64a049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d7690-a290-4b3f-9ed1-c56d7551c541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de0ce3f0-b657-4bb7-929d-bec547f14488",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### For fun, do a differences of differences because I am lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d9cbc-a0b9-4283-adbb-6e3712702e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd6211-4d25-4fb7-8c06-523c7adbd514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_difference_of_differences_map(df_A, df_B, target_quantile_A, target_quantile_B, target_scenario):\n",
    "    colour_map = {\n",
    "        \"dry_days\": \"OrRd\",\n",
    "        \"wet_days\": \"GnBu\"\n",
    "    }\n",
    "    \n",
    "    target_col = f\"total_precip_{target_scenario}\"\n",
    "    df_merged = df_A.copy()\n",
    "    df_merged.rename(\n",
    "        columns={\n",
    "            f\"{target_col}_ALL\": f\"{target_col}_ALL_A\",\n",
    "            f\"{target_col}_HOT\": f\"{target_col}_HOT_A\",\n",
    "            f\"{target_col}_fraction\": f\"{target_col}_fraction_A\"\n",
    "        }, \n",
    "        inplace=True\n",
    "    )\n",
    "    df_merged[f\"{target_col}_ALL_B\"] = df_B[f\"{target_col}_ALL\"]\n",
    "    df_merged[f\"{target_col}_HOT_B\"] = df_B[f\"{target_col}_HOT\"]\n",
    "    df_merged[f\"{target_col}_fraction_B\"] = df_B[f\"{target_col}_fraction\"]\n",
    "    \n",
    "    df_merged[f\"{target_col}_HOT_diff\"] = df_merged[f\"{target_col}_HOT_A\"] - df_merged[f\"{target_col}_HOT_B\"]\n",
    "    df_merged[f\"{target_col}_ALL_diff\"] = df_merged[f\"{target_col}_ALL_A\"] - df_merged[f\"{target_col}_ALL_B\"]\n",
    "    \n",
    "    df_merged[f\"{target_col}_fraction\"] = (df_merged[f\"{target_col}_HOT_diff\"] / df_merged[f\"{target_col}_ALL_diff\"]).astype(float).round(2)\n",
    "    df_merged[f\"{target_col}_fraction_diff\"] = (df_merged[f\"{target_col}_fraction_A\"] - df_merged[f\"{target_col}_fraction_B\"]).astype(float).round(2)\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_merged, \n",
    "        x='longitude', \n",
    "        y='latitude', \n",
    "        color=f\"total_precip_{target_scenario}_fraction_diff\", \n",
    "        symbol_sequence=[\"circle\"], \n",
    "        height=900, \n",
    "        width=900,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_map[target_scenario],\n",
    "        # range_color=(-0.05, 0.10)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Fraction Precipitation Difference (HOT / ALL) {target_scenario.replace('_', ' ')} [ {target_quantile_A}th quantile - {target_quantile_B}th quantile]\",\n",
    "        yaxis_title=None,\n",
    "        xaxis_title=None\n",
    "    )\n",
    "    \n",
    "    # fig.update_xaxes(visible=False)\n",
    "    # fig.update_yaxes(visible=False)\n",
    "    \n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7656c986-4244-4259-a5c0-4036dabaee23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5864ad-fc88-4e79-ae4c-058445459ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b829170-7fe9-48e2-ae59-bdc057855142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantile_A = 90\n",
    "quantile_B = 50\n",
    "\n",
    "df_A = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == quantile_A].copy().reset_index(drop=True)\n",
    "df_B = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == quantile_B].copy().reset_index(drop=True)\n",
    "\n",
    "fig_wet = plot_difference_of_differences_map(df_A, df_B, quantile_A, quantile_B, \"wet_days\")\n",
    "fig_dry = plot_difference_of_differences_map(df_A, df_B, quantile_A, quantile_B, \"dry_days\")\n",
    "\n",
    "fig_wet.show()\n",
    "fig_dry.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e516a-e213-4004-957d-4cdf43dc9da8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c74a2-6c20-4602-b6b1-0627f862355e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66377043-f2af-4ea2-be08-8f19d0cac465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "affd6ba5-2fa7-4ecc-ad86-c9698385cb1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Luke made some histograms for just Northland, recreate those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0213d-7836-4607-a32f-13eeff41a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_northland = df.loc[(df[\"region\"] == \"Northland Region\") & (df[\"grid_cell\"] == \"-35.995018_174.70364\")].copy().reset_index(drop=True)\n",
    "\n",
    "df_northland[\"days_wet\"] = df_northland[\"grid_cell\"].map(fixed_precip_grid_cell_map_wet)\n",
    "df_northland[\"days_dry\"] = df_northland[\"grid_cell\"].map(fixed_precip_grid_cell_map_dry)\n",
    "\n",
    "df_northland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900320f2-8a2b-4e28-87ee-2482849127f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_ = df_merged.loc[df_merged[\"grid_cell\"] == \"-35.995018_174.70364\"]\n",
    "df_merged_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2122b1-ba37-4221-8998-1590b5f0ed54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_northland, \n",
    "    x='total_precip_dry_days', \n",
    "    color='source', \n",
    "    barmode='overlay', \n",
    "    nbins=100, \n",
    "    height=600, \n",
    "    width=1000, \n",
    "    range_y=(0, 300), \n",
    "    range_x=(0, 600), \n",
    "    opacity=0.7,\n",
    "    template=\"plotly_white\",\n",
    "    title=\"Northland - driest 322 days\"\n",
    ")\n",
    "\n",
    "fig.add_shape(type='line', x0=179, x1=179, y0=0, y1=250, opacity=0.8, line=dict(color='green', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=202, x1=202, y0=0, y1=250, opacity=0.8, line=dict(color='green', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=243, x1=243, y0=0, y1=250, opacity=0.8, line=dict(color='brown', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=271, x1=271, y0=0, y1=250, opacity=0.8, line=dict(color='brown', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=265, x1=265, y0=0, y1=300, opacity=0.8, line=dict(color='black', width=6, dash='solid'), xref='x', yref='y', layer='above')\n",
    "\n",
    "fig.update_traces(marker_line_width=1,marker_line_color=\"black\")\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d30ba-4228-462a-8697-b56db25912d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_northland, \n",
    "    x='total_precip_wet_days', \n",
    "    color='source', \n",
    "    barmode='overlay', \n",
    "    nbins=100, \n",
    "    height=600, \n",
    "    width=1000, \n",
    "    range_y=(0, 300), \n",
    "    range_x=(0, 600), \n",
    "    opacity=0.7,\n",
    "    template=\"plotly_white\",\n",
    "    title=\"Northland - wettest 5 days\"\n",
    ")\n",
    "\n",
    "fig.add_shape(type='line', x0=269, x1=269, y0=0, y1=250, opacity=0.9, line=dict(color='green', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=296, x1=296, y0=0, y1=250, opacity=0.9, line=dict(color='green', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=369, x1=369, y0=0, y1=250, opacity=0.9, line=dict(color='purple', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=415, x1=415, y0=0, y1=250, opacity=0.9, line=dict(color='purple', width=4, dash='solid'), xref='x', yref='y', layer='above')\n",
    "fig.add_shape(type='line', x0=265, x1=265, y0=0, y1=300, opacity=0.9, line=dict(color='black', width=6, dash='solid'), xref='x', yref='y', layer='above')\n",
    "\n",
    "fig.update_traces(marker_line_width=1,marker_line_color=\"black\")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a96c4-4f7e-4a14-b82d-c5e81b4f1ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab587e5-4ca1-454e-a5b0-741cb0db56bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d20d6cfe-3eca-4705-b35e-f2aaf82c357b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Comparing percentiles - Grid-Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c9a49-3bd0-4251-9f2b-8c593f09158a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grid_cell_determine_model_quantiles(df: pd.DataFrame, target_col: str):\n",
    "    # Step: Sort column(s) total_precip_wet_days ascending (A-Z)\n",
    "    df = df.sort_values(by=[target_col], ascending=[True])\n",
    "\n",
    "    # Step: Split into ALL and HOT\n",
    "    df_ALL = df.loc[df[\"source\"] == \"ALL\"]\n",
    "    df_HOT = df.loc[df[\"source\"] == \"HOT\"]\n",
    "\n",
    "    # Step: Bin these based on wet precip column\n",
    "    df_ALL[\"quantile\"] = pd.qcut(df_ALL[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "    df_HOT[\"quantile\"] = pd.qcut(df_HOT[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "    \n",
    "    # Step: Group them by quantile\n",
    "    cols = [\"quantile\", target_col]\n",
    "    df_ALL = df_ALL[cols].groupby(by=[\"quantile\"]).median().reset_index(drop=False)\n",
    "    df_HOT = df_HOT[cols].groupby(by=[\"quantile\"]).median().reset_index(drop=False)\n",
    "    \n",
    "    # Step: Merge them into one\n",
    "    df_merged = df_HOT.merge(\n",
    "        right=df_ALL,\n",
    "        on=[\"quantile\"],\n",
    "        suffixes=[\"_HOT\", \"_ALL\"]\n",
    "    )\n",
    "    \n",
    "    # Step: Determine differences\n",
    "    df_merged[\"difference\"] = df_merged[f\"{target_col}_HOT\"] / df_merged[f\"{target_col}_ALL\"]\n",
    "    \n",
    "    return df_merged\n",
    "\n",
    "\n",
    "\n",
    "def grid_cell_plot_quantile_difference(df:pd.DataFrame, target_col: str, grid_cell: str, region_name: str, num_days: str):\n",
    "    colour_map = {\n",
    "        \"total_precip_wet_days\": \"rgba(200, 0, 150, 0.8)\",\n",
    "        \"total_precip_dry_days\": \"rgba(200, 100, 0, 0.8)\"\n",
    "    }\n",
    "    \n",
    "    fig = px.line(\n",
    "        df.sort_values(by=['quantile'], ascending=[True]), \n",
    "        x='quantile', \n",
    "        y='difference', \n",
    "        template='plotly_white', \n",
    "        range_y=(0.8, 1.2), \n",
    "        height=400,\n",
    "        width=700,\n",
    "        title=f\"Grid_cell: {grid_cell} [ {region_name} ]\"\n",
    "    )\n",
    "\n",
    "    fig.update_traces(mode=\"lines+markers\", line_color=colour_map[target_col])\n",
    "    \n",
    "    fig.update_yaxes(title=f\"{target_col.replace('_', ' ').upper()} {num_days} days\")\n",
    "    fig.update_xaxes(title=\"Ranked W@H Simulation (percentiles)\")\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fdb16-3fee-4519-a819-d41e32f686b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3b96b-311a-44ec-91c2-84d6b3385b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7fd1f-7e4b-4992-b10b-49c0cde945b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"There are {len(df['grid_cell'].unique())} unique grid-cells\")\n",
    "\n",
    "grid_cell_day_map = load(open(f\"{DIR_HAPPI}/RVI/fixed_precip_grid_cell_map.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a6a9c-9371-4794-97de-cea3198b2c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c5b4c-ee42-4f67-b47e-2fc205897173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_name = \"Northland Region\"\n",
    "\n",
    "for grid_cell in tqdm(df.loc[df[\"region\"] == region_name][\"grid_cell\"].unique()[:1]):\n",
    "    df_single_grid = df.loc[df[\"grid_cell\"] == grid_cell]\n",
    "    day_map_result = grid_cell_day_map[grid_cell]\n",
    "    \n",
    "    target_col = \"total_precip_wet_days\"\n",
    "    df_quantiles = grid_cell_determine_model_quantiles(df_single_grid, target_col)\n",
    "    grid_cell_plot_quantile_difference(df_quantiles, target_col, grid_cell, region_name, int(day_map_result[\"wet\"])).show()\n",
    "    \n",
    "    target_col = \"total_precip_dry_days\"\n",
    "    df_quantiles = grid_cell_determine_model_quantiles(df_single_grid, target_col)\n",
    "    grid_cell_plot_quantile_difference(df_quantiles, target_col, grid_cell, region_name, int(day_map_result[\"dry\"])).show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99ff3e-09c5-4f8e-bdd9-2d3fcd7ecff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa0265-a963-4601-a74c-36331804522d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1f3d8-f7db-42a0-bfdf-5b5fe220bf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267884e-679d-479f-99fb-36c4a736436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21fd28c3-a8f7-4b66-9e29-721919803094",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Comparing Percentiles - Total Yearly Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e58b2-ba0e-49ee-9d34-39b82948b0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_json_to_disk(data, parent_dir, file_name):\n",
    "    makedirs(parent_dir, exist_ok=True)\n",
    "    file_path = f\"{parent_dir}/{file_name}.json\"\n",
    "    with open(file_path, \"w\") as f_out:\n",
    "        f_out.write(dumps(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5090d5-5091-4e94-b800-9978b718ed43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6707474-981e-4acb-bfab-57a15d351665",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Read in the daily precip data and group into grid_cell and model_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115808a1-de48-4c82-becd-a516365dc73f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel = [(\"region\", \"!=\", \"Area Outside Region\")]\n",
    "\n",
    "df = pd.read_parquet(f\"{DIR_HAPPI}/Processed/\", filters=sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59e4e6-7376-427c-bdc7-356c797be9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e2df9-8743-4656-9ada-f928945f06e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b48dd49-9408-4425-b3fe-5d68b00dd302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"sim\",\n",
    "    \"model_tag\",\n",
    "    \"region\",\n",
    "    \"grid_cell\"\n",
    "]\n",
    "\n",
    "target_col = \"precip_mm\"\n",
    "\n",
    "df_grouped = df[group_cols + [target_col]].groupby(by=group_cols).sum().reset_index()\n",
    "\n",
    "df_grouped = df_grouped.loc[df_grouped[target_col] > 0].reset_index(drop=True)\n",
    "\n",
    "for col in tqdm(group_cols):\n",
    "    df_grouped[col] = df_grouped[col].astype(str)\n",
    "\n",
    "df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b13d6-6967-4196-8e97-1b0ca42d97be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96105923-fae3-4c84-acba-9270c363fcf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quickly grab the climatology expected mean / median precip to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf27f0e-8028-4123-8765-33beb59e4633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_climatology = df_grouped.loc[df_grouped[\"sim\"] == \"ALL\"].copy().reset_index(drop=True)\n",
    "\n",
    "climatology_precip_mean = df_climatology[target_col].mean()\n",
    "climatology_precip_median = df_climatology[target_col].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc779d-5467-4a10-8c6a-c346d3f942a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "climatology_precip_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058d7c5-03f6-4b2c-96fe-a4744392fef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "climatology_precip_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fbcb31-8a23-4773-b924-4b8817296469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "314045b5-8b3b-45ed-8df2-177ac63d6999",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Determine expected regional annual precipitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c844b-514b-461d-8c83-a861222610b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"sim\",\n",
    "    \"region\"\n",
    "]\n",
    "\n",
    "df_regions = df_grouped[group_cols + [target_col]].groupby(by=group_cols).median().reset_index()\n",
    "\n",
    "expected_precip_map_region = {}\n",
    "\n",
    "for i in range(0, df_regions.shape[0]):\n",
    "    row = df_regions.iloc[i]\n",
    "    \n",
    "    key_region = str(row[\"region\"])\n",
    "    key_sim = str(row[\"sim\"])\n",
    "    value_precip = round(float(row[target_col]), 2)\n",
    "    \n",
    "    if key_region not in expected_precip_map_region:\n",
    "        expected_precip_map_region[key_region] = {\"ALL\": value_precip, \"HOT\": 0.0}\n",
    "    else:\n",
    "        expected_precip_map_region[key_region][key_sim] = value_precip\n",
    "\n",
    "expected_precip_map_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca9778-6a77-426f-970c-5e10b9ab5c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_json_to_disk(expected_precip_map_region, DIR_HAPPI, \"expected_annual_rainfall_region_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873af69-5a19-4c62-aac8-a177e1a644b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3dc565b-d6a8-4044-bbab-ddfbe164014e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Determine model rankings (quantiles) - region based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d0d29-0808-4666-9ecc-917308cab7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regional_model_quantiles_ALL = {}\n",
    "regional_model_quantiles_HOT = {}\n",
    "\n",
    "regional_model_quantiles = {\n",
    "    # ALL\n",
    "    \"Percentile 05 - ALL\": {},\n",
    "    \"Percentile 10 - ALL\": {},\n",
    "    \"Percentile 50 - ALL\": {},\n",
    "    \"Percentile 90 - ALL\": {},\n",
    "    \"Percentile 95 - ALL\": {},\n",
    "    # HOT\n",
    "    \"Percentile 05 - HOT\": {},\n",
    "    \"Percentile 10 - HOT\": {},\n",
    "    \"Percentile 50 - HOT\": {},\n",
    "    \"Percentile 90 - HOT\": {},\n",
    "    \"Percentile 95 - HOT\": {},\n",
    "}\n",
    "\n",
    "group_cols = [\n",
    "    \"sim\",\n",
    "    \"model_tag\",\n",
    "    \"region\"\n",
    "]\n",
    "df_models = df_grouped[group_cols + [target_col]].groupby(by=group_cols).mean().reset_index()\n",
    "\n",
    "for region in tqdm(df_models[\"region\"].unique(), desc=\"Region Loop\", leave=1):\n",
    "    df_region = df_models.loc[df_models[\"region\"] == region].copy().sort_values(by=[target_col]).reset_index(drop=True)\n",
    "    \n",
    "    df_models_ALL = df_region.loc[df_region[\"sim\"] == \"ALL\"].copy()\n",
    "    df_models_HOT = df_region.loc[df_region[\"sim\"] == \"HOT\"].copy()\n",
    "\n",
    "    df_models_ALL[\"quantile\"] = pd.qcut(df_models_ALL[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "    df_models_HOT[\"quantile\"] = pd.qcut(df_models_HOT[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "    \n",
    "    for values in df_models_ALL.values:\n",
    "        region_name = values[2]\n",
    "        model_name = values[1]\n",
    "        quantile = values[4]\n",
    "\n",
    "        if region_name not in regional_model_quantiles_ALL.keys():\n",
    "            regional_model_quantiles_ALL[region_name] = {}\n",
    "            regional_model_quantiles[\"Percentile 05 - ALL\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 10 - ALL\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 50 - ALL\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 90 - ALL\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 95 - ALL\"][region_name] = []\n",
    "\n",
    "        if quantile == 5:\n",
    "            regional_model_quantiles[\"Percentile 05 - ALL\"][region_name].append(model_name)\n",
    "        elif quantile == 10:\n",
    "            regional_model_quantiles[\"Percentile 10 - ALL\"][region_name].append(model_name)\n",
    "        elif quantile == 50:\n",
    "            regional_model_quantiles[\"Percentile 50 - ALL\"][region_name].append(model_name)\n",
    "        elif quantile == 90:\n",
    "            regional_model_quantiles[\"Percentile 90 - ALL\"][region_name].append(model_name)\n",
    "        elif quantile == 95:\n",
    "            regional_model_quantiles[\"Percentile 95 - ALL\"][region_name].append(model_name)\n",
    "\n",
    "        regional_model_quantiles_ALL[region_name][model_name] = quantile\n",
    "    \n",
    "    for values in df_models_HOT.values:\n",
    "        region_name = values[2]\n",
    "        model_name = values[1]\n",
    "        quantile = values[4]\n",
    "\n",
    "        if region_name not in regional_model_quantiles_HOT.keys():\n",
    "            regional_model_quantiles_HOT[region_name] = {}\n",
    "            regional_model_quantiles[\"Percentile 05 - HOT\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 10 - HOT\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 50 - HOT\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 90 - HOT\"][region_name] = []\n",
    "            regional_model_quantiles[\"Percentile 95 - HOT\"][region_name] = []\n",
    "\n",
    "        if quantile == 5:\n",
    "            regional_model_quantiles[\"Percentile 05 - HOT\"][region_name].append(model_name)\n",
    "        elif quantile == 10:\n",
    "            regional_model_quantiles[\"Percentile 10 - HOT\"][region_name].append(model_name)\n",
    "        elif quantile == 50:\n",
    "            regional_model_quantiles[\"Percentile 50 - HOT\"][region_name].append(model_name)\n",
    "        elif quantile == 90:\n",
    "            regional_model_quantiles[\"Percentile 90 - HOT\"][region_name].append(model_name)\n",
    "        elif quantile == 95:\n",
    "            regional_model_quantiles[\"Percentile 95 - HOT\"][region_name].append(model_name)\n",
    "\n",
    "        regional_model_quantiles_HOT[region_name][model_name] = quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab15811-f67a-4296-922c-e015801cf9df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_json_to_disk(regional_model_quantiles_ALL, DIR_HAPPI, \"regional_model_quantiles_ALL\")\n",
    "write_json_to_disk(regional_model_quantiles_HOT, DIR_HAPPI, \"regional_model_quantiles_HOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddef606-fc9e-4531-b75a-8c0263829111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38ad7a-bf76-45e9-8912-b91140a2b437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2416d8-cfbb-4987-a132-9ecb94938b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_dfs = []\n",
    "\n",
    "for source in tqdm([\"ALL\", \"HOT\"], desc=\"Source Loop\", leave=1):\n",
    "    for region_name in tqdm(df[\"region\"].unique(), desc=\"Region Loop\", leave=1):\n",
    "        df_region = df.loc[\n",
    "            (df[\"region\"] == region_name) &\n",
    "            (df[\"sim\"] == source) \n",
    "        ].copy()\n",
    "\n",
    "        df_region[\"model_tag\"] = df_region[\"model_tag\"].astype(str)\n",
    "\n",
    "        dfs = []\n",
    "\n",
    "        for classification in tqdm([\n",
    "            f\"Percentile 05 - {source}\",\n",
    "            f\"Percentile 10 - {source}\",\n",
    "            f\"Percentile 50 - {source}\",\n",
    "            f\"Percentile 90 - {source}\",\n",
    "            f\"Percentile 95 - {source}\"\n",
    "        ], desc=\"Percentile Loop\", leave=0):\n",
    "\n",
    "            df_percentile = df_region.loc[df_region[\"model_tag\"].isin(regional_model_quantiles[classification][region_name])].copy()\n",
    "\n",
    "\n",
    "            for model_tag in df_percentile[\"model_tag\"].unique():\n",
    "                df_model = df_percentile.loc[df_percentile[\"model_tag\"] == model_tag].copy()\n",
    "\n",
    "                df_model[\"day\"] = df_model[\"time1\"].str[8:10]\n",
    "                group_cols = [\"model_tag\", \"month\", \"day\"]\n",
    "                df_model = df_model[group_cols + [target_col]].groupby(group_cols).median().reset_index(drop=False)\n",
    "\n",
    "                df_model.sort_values(by=[\"model_tag\", target_col], ascending=False, inplace=True)\n",
    "                df_model = df_model.reset_index(drop=True).reset_index(drop=False)\n",
    "\n",
    "                df_model[\"cumulative_precip\"] = df_model[target_col].cumsum()\n",
    "                \n",
    "                # ====================================================================\n",
    "                # This can be done mulitple ways we should discuss this\n",
    "                # df_model[\"percent_of_annual_rainfall\"] = df_model[\"cumulative_precip\"] / expected_precip_map_region[region_name][\"ALL\"] # Expected current decade region total \n",
    "                df_model[\"percent_of_annual_rainfall\"] = df_model[\"cumulative_precip\"] / climatology_precip_median # Entire country and climatology total\n",
    "                \n",
    "                df_model.rename(columns={\"index\": \"precip_rank\"}, inplace=True)\n",
    "                df_model[\"classification\"] = classification\n",
    "                dfs.append(df_model)\n",
    "\n",
    "        df_temp = pd.concat(dfs)\n",
    "\n",
    "        group_cols = [\"precip_rank\", \"classification\"]\n",
    "        df_temp = df_temp[group_cols + [\"cumulative_precip\", \"percent_of_annual_rainfall\"]].groupby(group_cols).median().reset_index(drop=False)\n",
    "        \n",
    "        # Add in metadata\n",
    "        df_temp[\"region\"] = region_name\n",
    "        df_temp[\"source\"] = source\n",
    "        \n",
    "        summary_dfs.append(df_temp)\n",
    "        \n",
    "df_summary = pd.concat(summary_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8779b3-81ae-45dc-97ae-9e7ace19a77b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5440817-0095-48a8-8b94-d6df3cbceb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75f3fd-e19e-4d03-9c7b-6734a314b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def total_year_determine_model_quantiles(df: pd.DataFrame, target_col: str):\n",
    "#     # Step: Sort column(s) total_precip_wet_days ascending (A-Z)\n",
    "#     df = df.sort_values(by=[target_col], ascending=[True])\n",
    "\n",
    "#     # Step: Split into ALL and HOT\n",
    "#     df_ALL = df.loc[df[\"source\"] == \"ALL\"]\n",
    "#     df_HOT = df.loc[df[\"source\"] == \"HOT\"]\n",
    "    \n",
    "#     # Step: Group them by ensemble member\n",
    "#     group_cols = [\n",
    "#         \"model\"\n",
    "#     ]\n",
    "#     df_ALL = df[]\n",
    "    \n",
    "\n",
    "#     # Step: Bin these based on wet precip column\n",
    "#     df_ALL[\"quantile\"] = pd.qcut(df_ALL[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "#     df_HOT[\"quantile\"] = pd.qcut(df_HOT[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "    \n",
    "#     # Step: Group them by quantile\n",
    "#     cols = [\"quantile\", target_col]\n",
    "#     df_ALL = df_ALL[cols].groupby(by=[\"quantile\"]).median().reset_index(drop=False)\n",
    "#     df_HOT = df_HOT[cols].groupby(by=[\"quantile\"]).median().reset_index(drop=False)\n",
    "    \n",
    "#     # Step: Merge them into one\n",
    "#     df_merged = df_HOT.merge(\n",
    "#         right=df_ALL,\n",
    "#         on=[\"quantile\"],\n",
    "#         suffixes=[\"_HOT\", \"_ALL\"]\n",
    "#     )\n",
    "    \n",
    "#     # Step: Determine differences\n",
    "#     df_merged[\"difference\"] = df_merged[f\"{target_col}_HOT\"] / df_merged[f\"{target_col}_ALL\"]\n",
    "    \n",
    "#     return df_merged\n",
    "\n",
    "\n",
    "\n",
    "def total_year_plot_quantile_difference(df:pd.DataFrame, target_col: str, region_name: str):\n",
    "    colour_map = {\n",
    "        \"ALL\": \"rgba(210, 40, 210, 0.9)\",\n",
    "        \"HOT\": \"rgba(210, 10, 10, 0.9)\",\n",
    "        \"OBS\": \"rgba(50, 50, 200, 0.9)\",\n",
    "    }\n",
    "    \n",
    "    width_map = {\n",
    "        \"05\": 2,\n",
    "        \"10\": 2,\n",
    "        \"50\": 4,\n",
    "        \"90\": 2,\n",
    "        \"95\": 2,\n",
    "    }\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for source in df[\"source\"].unique():\n",
    "        df_source = df.loc[df[\"source\"] == source]\n",
    "        for classification in df_source[\"classification\"].unique():\n",
    "            quantile = re.findall(r\"Percentile (.*?) -\", classification)[0]\n",
    "            df_temp = df_source.loc[df_source[\"classification\"] == classification]\n",
    "            fig.add_trace(\n",
    "                go.Line( \n",
    "                    x=df_temp[\"precip_rank\"],\n",
    "                    y=df_temp[target_col],\n",
    "                    line=dict(color=colour_map[source], width=width_map[quantile]),\n",
    "                    name=classification\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Region: {region_name} Summary plot\",\n",
    "        height=600, \n",
    "        width=900,\n",
    "        xaxis_range=[0, 30],\n",
    "        yaxis_range=[0, 0.8]\n",
    "    )\n",
    "    \n",
    "    # fig.update_traces(mode=\"lines\", line_color=colour_map[\"HOT\"])\n",
    "    \n",
    "    fig.update_yaxes(title=\"Cumulative fraction of annual rainfall <br> (with \\\"annual\\\" fixed as climatology)\")\n",
    "    fig.update_xaxes(title=\"Number of days of rain required\")\n",
    "    \n",
    "    return fig                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fb214-5e71-4386-97e6-75ec95c809b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81dc5d0-b3a1-4c88-a3f1-4441d9d0f213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_name = \"Auckland Region\"\n",
    "\n",
    "df_sample = df_summary.loc[\n",
    "    (df_summary[\"region\"] == region_name) \n",
    "    # (df_summary[\"source\"] == \"HOT\")\n",
    "]\n",
    "\n",
    "total_year_plot_quantile_difference(df_sample, \"percent_of_annual_rainfall\", region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865ef33-b2d6-41d5-82a2-7c44cba5dc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d80348-fa76-48e8-9968-e8f901b643ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Determine model rankings (quantiles) - whole country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbda1f5-ca23-4c81-8955-0608c9712ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country_model_quantiles_ALL = {}\n",
    "country_model_quantiles_HOT = {}\n",
    "\n",
    "country_model_quantiles = {\n",
    "    # ALL\n",
    "    \"Percentile 05 - ALL\": [],\n",
    "    \"Percentile 10 - ALL\": [],\n",
    "    \"Percentile 50 - ALL\": [],\n",
    "    \"Percentile 90 - ALL\": [],\n",
    "    \"Percentile 95 - ALL\": [],\n",
    "    # HOT\n",
    "    \"Percentile 05 - HOT\": [],\n",
    "    \"Percentile 10 - HOT\": [],\n",
    "    \"Percentile 50 - HOT\": [],\n",
    "    \"Percentile 90 - HOT\": [],\n",
    "    \"Percentile 95 - HOT\": [],\n",
    "}\n",
    "\n",
    "group_cols = [\n",
    "    \"sim\",\n",
    "    \"model_tag\"\n",
    "]\n",
    "df_models = df_grouped[group_cols + [target_col]].groupby(by=group_cols).mean().reset_index()\n",
    "df_models = df_models.sort_values(by=[target_col]).reset_index(drop=True)\n",
    "\n",
    "df_models_ALL = df_models.loc[df_models[\"sim\"] == \"ALL\"].copy()\n",
    "df_models_HOT = df_models.loc[df_models[\"sim\"] == \"HOT\"].copy()\n",
    "\n",
    "df_models_ALL[\"quantile\"] = pd.qcut(df_models_ALL[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "df_models_HOT[\"quantile\"] = pd.qcut(df_models_HOT[target_col], q=100, labels=np.arange(1, 101, 1))\n",
    "\n",
    "for values in df_models_ALL.values:\n",
    "    model_name = values[1]\n",
    "    quantile = values[3]\n",
    "\n",
    "    if quantile == 5:\n",
    "        country_model_quantiles[\"Percentile 05 - ALL\"].append(model_name)\n",
    "    elif quantile == 10:\n",
    "        country_model_quantiles[\"Percentile 10 - ALL\"].append(model_name)\n",
    "    elif quantile == 50:\n",
    "        country_model_quantiles[\"Percentile 50 - ALL\"].append(model_name)\n",
    "    elif quantile == 90:\n",
    "        country_model_quantiles[\"Percentile 90 - ALL\"].append(model_name)\n",
    "    elif quantile == 95:\n",
    "        country_model_quantiles[\"Percentile 95 - ALL\"].append(model_name)\n",
    "\n",
    "    country_model_quantiles_ALL[model_name] = quantile\n",
    "\n",
    "for values in df_models_HOT.values:\n",
    "    model_name = values[1]\n",
    "    quantile = values[3]\n",
    "\n",
    "    if quantile == 5:\n",
    "        country_model_quantiles[\"Percentile 05 - HOT\"].append(model_name)\n",
    "    elif quantile == 10:\n",
    "        country_model_quantiles[\"Percentile 10 - HOT\"].append(model_name)\n",
    "    elif quantile == 50:\n",
    "        country_model_quantiles[\"Percentile 50 - HOT\"].append(model_name)\n",
    "    elif quantile == 90:\n",
    "        country_model_quantiles[\"Percentile 90 - HOT\"].append(model_name)\n",
    "    elif quantile == 95:\n",
    "        country_model_quantiles[\"Percentile 95 - HOT\"].append(model_name)\n",
    "\n",
    "    country_model_quantiles_HOT[model_name] = quantile\n",
    "\n",
    "    \n",
    "df_models_ALL[\"quantile\"] = df_models_ALL[\"quantile\"].astype(str)\n",
    "df_models_HOT[\"quantile\"] = df_models_HOT[\"quantile\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf192ad-5f85-41e9-95d0-c778367f264a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_json_to_disk(country_model_quantiles_ALL, DIR_HAPPI, \"country_model_quantiles_ALL\")\n",
    "write_json_to_disk(country_model_quantiles_HOT, DIR_HAPPI, \"country_model_quantiles_HOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2caf89-8601-47ec-b910-f8ffea5280a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90b024-033d-45ea-b74a-40dec4fda7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = \"50\"\n",
    "\n",
    "group_cols = [\n",
    "    \"grid_cell\",\n",
    "]\n",
    "\n",
    "target_col = \"precip_mm\"\n",
    "\n",
    "target_models_ALL = df_models_ALL.loc[df_models_ALL[\"quantile\"] == target_quantile][\"model_tag\"].values\n",
    "target_models_HOT = df_models_HOT.loc[df_models_HOT[\"quantile\"] == target_quantile][\"model_tag\"].values\n",
    "\n",
    "df_ALL_grouped = df_grouped.loc[df_grouped[\"model_tag\"].isin(target_models_ALL)][group_cols + [target_col]].groupby(by=group_cols).median().reset_index()\n",
    "df_HOT_grouped = df_grouped.loc[df_grouped[\"model_tag\"].isin(target_models_HOT)][group_cols + [target_col]].groupby(by=group_cols).median().reset_index()\n",
    "\n",
    "df_merged = df_HOT_grouped.merge(\n",
    "    right=df_ALL_grouped,\n",
    "    how=\"left\",\n",
    "    on=\"grid_cell\",\n",
    "    suffixes=[\"_HOT\", \"_ALL\"]\n",
    ")\n",
    "\n",
    "df_merged[\"precip_mm_diff\"] = df_merged[\"precip_mm_HOT\"] / df_merged[\"precip_mm_ALL\"]\n",
    "df_merged[\"precip_mm_diff\"] = df_merged[\"precip_mm_HOT\"] / df_merged[\"precip_mm_ALL\"]\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_merged[\"grid_cell\"].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"latitude\", \"longitude\"]\n",
    "df_merged = pd.merge(df_merged, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "df_merged[\"longitude\"] = df_merged[\"longitude\"].astype(float)\n",
    "df_merged[\"latitude\"] = df_merged[\"latitude\"].astype(float)\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcdfbf-0fa6-4581-8f24-d32ff80c7bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956e8ac-4ce9-490a-b9ae-bb116f9fc772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_country_difference_for_quantile(df_grouped: pd.DataFrame, df_models_ALL: pd.DataFrame, df_models_HOT: pd.DataFrame, target_quantile: str):\n",
    "    group_cols = [\"grid_cell\"]\n",
    "    target_col = \"precip_mm\"\n",
    "\n",
    "    target_models_ALL = df_models_ALL.loc[df_models_ALL[\"quantile\"] == target_quantile][\"model_tag\"].values\n",
    "    target_models_HOT = df_models_HOT.loc[df_models_HOT[\"quantile\"] == target_quantile][\"model_tag\"].values\n",
    "\n",
    "    df_ALL_grouped = df_grouped.loc[df_grouped[\"model_tag\"].isin(target_models_ALL)][group_cols + [target_col]].groupby(by=group_cols).median().reset_index()\n",
    "    df_HOT_grouped = df_grouped.loc[df_grouped[\"model_tag\"].isin(target_models_HOT)][group_cols + [target_col]].groupby(by=group_cols).median().reset_index()\n",
    "\n",
    "    df_merged = df_HOT_grouped.merge(\n",
    "        right=df_ALL_grouped,\n",
    "        how=\"left\",\n",
    "        on=\"grid_cell\",\n",
    "        suffixes=[\"_HOT\", \"_ALL\"]\n",
    "    )\n",
    "\n",
    "    df_merged[\"precip_mm_diff\"] = df_merged[\"precip_mm_HOT\"] / df_merged[\"precip_mm_ALL\"]\n",
    "    df_merged[\"precip_mm_diff\"] = df_merged[\"precip_mm_HOT\"] / df_merged[\"precip_mm_ALL\"]\n",
    "\n",
    "    # Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "    split_df = df_merged[\"grid_cell\"].str.split('_', n=2, expand=True)\n",
    "    split_df.columns = [\"latitude\", \"longitude\"]\n",
    "    df_merged = pd.merge(df_merged, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "    df_merged[\"longitude\"] = df_merged[\"longitude\"].astype(float)\n",
    "    df_merged[\"latitude\"] = df_merged[\"latitude\"].astype(float)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "\n",
    "def plot_country_difference_map(df_merged, quantile):\n",
    "    if int(quantile) < 50:\n",
    "        chosen_colour_map = \"OrRd\"\n",
    "    elif int(quantile) == 50:\n",
    "        chosen_colour_map = \"RdBu\"\n",
    "    else:\n",
    "        chosen_colour_map = \"GnBu\"\n",
    "    \n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_merged, \n",
    "        x='longitude', \n",
    "        y='latitude', \n",
    "        color='precip_mm_diff', \n",
    "        symbol_sequence=['circle'], \n",
    "        height=800, \n",
    "        width=800,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=chosen_colour_map,\n",
    "        range_color=(0.8, 1.2)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(title=f\"Fraction Precipitation Difference (HOT / ALL) for the quantile {quantile} ensemble members\")\n",
    "\n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def plot_country_difference_map_geo(df_merged, quantile):\n",
    "    if int(quantile) < 50:\n",
    "        chosen_colour_map = \"OrRd\"\n",
    "    elif int(quantile) == 50:\n",
    "        chosen_colour_map = \"RdBu\"\n",
    "    else:\n",
    "        chosen_colour_map = \"GnBu\"\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scattergeo( \n",
    "            lon=df_merged['longitude'], \n",
    "            lat=df_merged['latitude'], \n",
    "            # color=df_merged['precip_mm_diff'], \n",
    "            symbol_sequence=['circle'], \n",
    "            height=800, \n",
    "            width=800,\n",
    "            template=\"plotly_white\",\n",
    "            color_continuous_scale=chosen_colour_map,\n",
    "            range_color=(0.8, 1.2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(title=f\"Fraction Precipitation Difference (HOT / ALL) for the quantile {quantile} ensemble members\")\n",
    "\n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0072612-ae2b-4a35-a956-29262e49700c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = \"90\"\n",
    "df_merged = determine_country_difference_for_quantile(df_grouped, df_models_ALL, df_models_HOT, target_quantile)\n",
    "plot_country_difference_map(df_merged, target_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d5af3-5a38-4ba1-9e33-e7aaa6b2d631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = \"10\"\n",
    "df_merged = determine_country_difference_for_quantile(df_grouped, df_models_ALL, df_models_HOT, target_quantile)\n",
    "plot_country_difference_map(df_merged, target_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65018aa-db2b-42a5-b383-472cb43212c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f930d2a-f4b1-431e-8c6d-41a71b44e00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09bb4aa-a659-4a45-83ff-8a8177c95131",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part 5 - Sensitivity tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53502316-0640-45d0-be9d-d576db056453",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## RxDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff463d7d-8f4e-45c6-a4d4-d6bfe06ae9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_quantiles_for_rx_data(df_ALL, df_HOT, num_quantiles=100):\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each grid cell\n",
    "    for grid_cell in tqdm(df_ALL[\"grid_cell\"].unique(), desc=\"Grid_cell Loop\"):\n",
    "        # Filter to that grid cell data\n",
    "        df_temp_ALL = df_ALL.loc[df_ALL[\"grid_cell\"] == grid_cell].copy()\n",
    "        df_temp_HOT = df_HOT.loc[df_HOT[\"grid_cell\"] == grid_cell].copy()\n",
    "\n",
    "        # Determine wet quantiles\n",
    "        df_temp_ALL[\"wet_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"wet_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        \n",
    "        # Change the quantile cols to strings then integers as they start as objects\n",
    "        df_temp_ALL[\"wet_quantile\"] = df_temp_ALL[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"wet_quantile\"] = df_temp_HOT[\"wet_quantile\"].astype(str).astype(int)\n",
    "        \n",
    "        # ==================================================================================================================================\n",
    "        # I am quite tired and seem to have broken the \"merge\" function. I can't be bothered fixing it so this is a fast workaround\n",
    "\n",
    "        # Group by the quantiles taking the median of each quantile, this \"bins them\"\n",
    "        group_cols = [\n",
    "            \"grid_cell\",\n",
    "        ]\n",
    "        wet_cols = [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"wet_quantile\",\n",
    "        ]\n",
    "        df_ALL_wet = df_temp_ALL[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_HOT_wet = df_temp_HOT[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        \n",
    "        # Merge them back into one\n",
    "        df_merged = df_ALL_wet[group_cols]\n",
    "        for col in [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"wet_quantile\",\n",
    "        ]:\n",
    "            df_merged[f\"{col}_HOT\"] = df_HOT_wet[col]\n",
    "            df_merged[f\"{col}_ALL\"] = df_ALL_wet[col]\n",
    "        \n",
    "        # ==================================================================================================================================\n",
    "\n",
    "        # Determine total_precip_xxx_days_fraction here to save time\n",
    "        df_merged[\"total_precip_wet_days_fraction\"] = (df_merged[\"total_precip_wet_days_HOT\"] / df_merged[\"total_precip_wet_days_ALL\"]).astype(float).round(3)\n",
    "        \n",
    "        # Pull out the lon and lat values\n",
    "        grid_cell_parts = grid_cell.split(\"_\")\n",
    "        lat = float(grid_cell_parts[0])\n",
    "        lon = float(grid_cell_parts[1])\n",
    "        df_merged[\"longitude\"] = lon\n",
    "        df_merged[\"latitude\"] = lat\n",
    "\n",
    "        # Append this to the big list\n",
    "        dfs.append(df_merged)\n",
    "\n",
    "    # Concat all the dfs into one giga-one\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def plot_difference_map_rx_quantile(df_merged, target_quantile, target_scenario, rx):\n",
    "    colour_map = {\n",
    "        \"dry_days\": \"OrRd\",\n",
    "        \"wet_days\": \"GnBu\"\n",
    "    }\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_merged, \n",
    "        x='longitude', \n",
    "        y='latitude', \n",
    "        color=f\"total_precip_{target_scenario}_fraction\", \n",
    "        symbol_sequence=[\"circle\"], \n",
    "        height=900, \n",
    "        width=900,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_map[target_scenario],\n",
    "        range_color=(0.80, 1.25)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Rx{rx}Day Fraction Precipitation Difference (HOT / ALL) {target_scenario.replace('_', ' ')} [ {target_quantile}th quantile ]\",\n",
    "        yaxis_title=None,\n",
    "        xaxis_title=None\n",
    "    )\n",
    "    \n",
    "    # fig.update_xaxes(visible=False)\n",
    "    # fig.update_yaxes(visible=False)\n",
    "    \n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487135f3-d87e-4f4c-8553-9ea4d8cbce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = [(\"region\", \"!=\", \"Area Outside Region\")]\n",
    "\n",
    "df = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_RX/\", filters=sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbd9514-3a37-4e50-93a1-13b32409d080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ALL = df.loc[df[\"source\"] == \"ALL\"].copy().reset_index(drop=True)\n",
    "df_HOT = df.loc[df[\"source\"] == \"HOT\"].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6cb5d2-faa6-40f2-9284-dd5f2f5cd7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged_1 = determine_quantiles_for_rx_data(df_ALL.loc[df_ALL[\"window\"] == 1].copy(), df_HOT.loc[df_HOT[\"window\"] == 1].copy())\n",
    "df_merged_3 = determine_quantiles_for_rx_data(df_ALL.loc[df_ALL[\"window\"] == 3].copy(), df_HOT.loc[df_HOT[\"window\"] == 3].copy())\n",
    "df_merged_5 = determine_quantiles_for_rx_data(df_ALL.loc[df_ALL[\"window\"] == 5].copy(), df_HOT.loc[df_HOT[\"window\"] == 5].copy())\n",
    "df_merged_7 = determine_quantiles_for_rx_data(df_ALL.loc[df_ALL[\"window\"] == 7].copy(), df_HOT.loc[df_HOT[\"window\"] == 7].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2cfe8-d296-4199-8f3c-9f0e816a3259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7181a07-b404-4056-816a-73b7bf3f7579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = 10\n",
    "\n",
    "df_quantile_1 = df_merged_1.loc[df_merged_1[\"wet_quantile_ALL\"] == target_quantile].copy()\n",
    "df_quantile_3 = df_merged_3.loc[df_merged_1[\"wet_quantile_ALL\"] == target_quantile].copy()\n",
    "df_quantile_5 = df_merged_5.loc[df_merged_1[\"wet_quantile_ALL\"] == target_quantile].copy()\n",
    "df_quantile_7 = df_merged_7.loc[df_merged_1[\"wet_quantile_ALL\"] == target_quantile].copy()\n",
    "\n",
    "fig_wet_1 = plot_difference_map_rx_quantile(df_quantile_1, target_quantile, \"wet_days\", 1)\n",
    "fig_wet_3 = plot_difference_map_rx_quantile(df_quantile_3, target_quantile, \"wet_days\", 3)\n",
    "fig_wet_5 = plot_difference_map_rx_quantile(df_quantile_5, target_quantile, \"wet_days\", 5)\n",
    "fig_wet_7 = plot_difference_map_rx_quantile(df_quantile_7, target_quantile, \"wet_days\", 7)\n",
    "\n",
    "fig_wet_1.show()\n",
    "fig_wet_3.show()\n",
    "fig_wet_5.show()\n",
    "fig_wet_7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a9249-d179-496e-977d-b9abf3768cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c670a9-1731-4420-ba0a-e00946f13633",
   "metadata": {},
   "source": [
    "## Constant fixed 5 wet 300 dry days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece1172-3877-4fc7-8ec2-53dc44ea2cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_quantiles_for_data(df_ALL, df_HOT, num_quantiles=100):\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each grid cell\n",
    "    for grid_cell in tqdm(df_ALL[\"grid_cell\"].unique(), desc=\"Grid_cell Loop\"):\n",
    "        # Filter to that grid cell data\n",
    "        df_temp_ALL = df_ALL.loc[df_ALL[\"grid_cell\"] == grid_cell].copy()\n",
    "        df_temp_HOT = df_HOT.loc[df_HOT[\"grid_cell\"] == grid_cell].copy()\n",
    "\n",
    "        # Determine wet and dry quantiles\n",
    "        df_temp_ALL[\"wet_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_ALL[\"dry_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_dry_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"wet_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"dry_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_dry_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "\n",
    "        # Change the quantile cols to strings then integers as they start as objects\n",
    "        df_temp_ALL[\"wet_quantile\"] = df_temp_ALL[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_ALL[\"dry_quantile\"] = df_temp_ALL[\"dry_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"wet_quantile\"] = df_temp_HOT[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"dry_quantile\"] = df_temp_HOT[\"dry_quantile\"].astype(str).astype(int)\n",
    "\n",
    "        # ==================================================================================================================================\n",
    "        # I am quite tired and seem to have broken the \"merge\" function. I can't be bothered fixing it so this is a fast workaround\n",
    "\n",
    "        # Group by the quantiles taking the median of each quantile, this \"bins them\"\n",
    "        group_cols = [\n",
    "            \"grid_cell\",\n",
    "            \"days_wet\",\n",
    "            \"days_dry\",\n",
    "        ]\n",
    "        wet_cols = [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"wet_quantile\",\n",
    "        ]\n",
    "        dry_cols = [\n",
    "            \"total_precip_dry_days\",\n",
    "            \"dry_quantile\"\n",
    "        ]\n",
    "        df_ALL_wet = df_temp_ALL[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_ALL_dry = df_temp_ALL[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "        df_ALL_wet[\"total_precip_dry_days\"] = df_ALL_dry[\"total_precip_dry_days\"]\n",
    "        df_ALL_wet[\"dry_quantile\"] = df_ALL_dry[\"dry_quantile\"]\n",
    "        df_HOT_wet = df_temp_HOT[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_HOT_dry = df_temp_HOT[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "        df_HOT_wet[\"total_precip_dry_days\"] = df_HOT_dry[\"total_precip_dry_days\"]\n",
    "        df_HOT_wet[\"dry_quantile\"] = df_HOT_dry[\"dry_quantile\"]\n",
    "\n",
    "        # Merge them back into one\n",
    "        df_merged = df_ALL_wet[group_cols]\n",
    "        for col in [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"total_precip_dry_days\",\n",
    "            \"wet_quantile\",\n",
    "            \"dry_quantile\",\n",
    "        ]:\n",
    "            if \"wet\" in col:\n",
    "                df_merged[f\"{col}_HOT\"] = df_HOT_wet[col]\n",
    "                df_merged[f\"{col}_ALL\"] = df_ALL_wet[col]\n",
    "            else:\n",
    "                df_merged[f\"{col}_HOT\"] = df_HOT_dry[col]\n",
    "                df_merged[f\"{col}_ALL\"] = df_ALL_dry[col]\n",
    "\n",
    "        # ==================================================================================================================================\n",
    "\n",
    "        # Determine total_precip_xxx_days_fraction here to save time\n",
    "        df_merged[\"total_precip_wet_days_fraction\"] = (df_merged[\"total_precip_wet_days_HOT\"] / df_merged[\"total_precip_wet_days_ALL\"]).astype(float).round(3)\n",
    "        df_merged[\"total_precip_dry_days_fraction\"] = (df_merged[\"total_precip_dry_days_HOT\"] / df_merged[\"total_precip_dry_days_ALL\"]).astype(float).round(3)\n",
    "        \n",
    "        \n",
    "        # Pull out the lon and lat values\n",
    "        grid_cell_parts = grid_cell.split(\"_\")\n",
    "        lat = float(grid_cell_parts[0])\n",
    "        lon = float(grid_cell_parts[1])\n",
    "        df_merged[\"longitude\"] = lon\n",
    "        df_merged[\"latitude\"] = lat\n",
    "\n",
    "        # Append this to the big list\n",
    "        dfs.append(df_merged)\n",
    "\n",
    "    # Concat all the dfs into one giga-one\n",
    "    return pd.concat(dfs)\n",
    "    \n",
    "\n",
    "\n",
    "def plot_difference_map_quantile(df_merged, target_quantile, target_scenario):\n",
    "    colour_map = {\n",
    "        \"dry_days\": \"OrRd\",\n",
    "        \"wet_days\": \"GnBu\"\n",
    "    }\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_merged, \n",
    "        x='longitude', \n",
    "        y='latitude', \n",
    "        color=f\"total_precip_{target_scenario}_fraction\", \n",
    "        symbol_sequence=[\"circle\"], \n",
    "        height=900, \n",
    "        width=900,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_map[target_scenario],\n",
    "        range_color=(0.80, 1.25)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Fraction Precipitation Difference (HOT / ALL) {target_scenario.replace('_', ' ')} [ {target_quantile}th quantile fixed 5 wet 300 dry days ]\",\n",
    "        yaxis_title=None,\n",
    "        xaxis_title=None\n",
    "    )\n",
    "    \n",
    "    # fig.update_xaxes(visible=False)\n",
    "    # fig.update_yaxes(visible=False)\n",
    "    \n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e4525-4f5f-48b8-b77e-ea6c81d8e02f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel = [(\"region\", \"!=\", \"Area Outside Region\")]\n",
    "\n",
    "df = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_Days_5_300/\", filters=sel)\n",
    "\n",
    "df_ALL = df.loc[df[\"source\"] == \"ALL\"].copy().reset_index(drop=True)\n",
    "df_HOT = df.loc[df[\"source\"] == \"HOT\"].copy().reset_index(drop=True)\n",
    "\n",
    "df_ALL[\"days_wet\"] = 5\n",
    "df_ALL[\"days_dry\"] = 300\n",
    "df_HOT[\"days_wet\"] = 5\n",
    "df_HOT[\"days_dry\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d11da6-0e42-45d1-b2c3-6e00d5a9e7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = determine_quantiles_for_data(df_ALL, df_HOT, num_quantiles=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec51bd2-7fc6-408a-aae4-6f45c574c21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.to_parquet(f\"{DIR_HAPPI}/RVI/fixed_day_5_300_grid_cell_quantiles.parquet\")\n",
    "\n",
    "df_merged.to_csv(f\"{DIR_HAPPI}/RVI/fixed_day_5_300_grid_cell_quantiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed44a2-df8a-496a-9c20-8915751e7b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ad3e6-e1b9-4796-b8ab-70a941b94aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec006e2-513c-4901-881f-03719ab4fafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750acd3-ae5e-46cd-8787-2d8cea16d2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_quantile = 50\n",
    "df_quantile = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == target_quantile].copy()\n",
    "\n",
    "fig_wet = plot_difference_map_quantile(df_quantile, target_quantile, \"wet_days\")\n",
    "fig_dry = plot_difference_map_quantile(df_quantile, target_quantile, \"dry_days\")\n",
    "\n",
    "fig_wet.show()\n",
    "fig_dry.show()\n",
    "\n",
    "fig_wet.write_html(f\"{DIR_PLOTS}/NZ_ratio_5_300_{target_quantile}th_quantile_wet.html\")\n",
    "fig_dry.write_html(f\"{DIR_PLOTS}/NZ_ratio_5_300_{target_quantile}th_quantile_dry.html\")\n",
    "\n",
    "fig_wet.write_image(f\"{DIR_PLOTS}/NZ_ratio_5_300_{target_quantile}th_quantile_wet.png\", format=\"png\", scale=2)\n",
    "fig_dry.write_image(f\"{DIR_PLOTS}/NZ_ratio_5_300_{target_quantile}th_quantile_dry.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38303a59-f046-46ae-b35e-21438dcc7ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc51af-8284-4449-8020-2cce4cc30ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5010fac-991b-47b6-be92-326315af8726",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Part X - Supporting Plots for Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c2ebf-786c-4142-958d-ea7d34bbf853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73acd1-92a3-4c89-b328-d54562ee3233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sel = [(\"region\", \"!=\", \"Area Outside Region\")]\n",
    "\n",
    "df = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_Days/\", filters=sel)\n",
    "\n",
    "target_regions = [\"Northland Region\", \"Tasman Region\", \"Southland Region\"]\n",
    "\n",
    "print(df[\"region\"].value_counts(normalize=True))\n",
    "\n",
    "# df = df.loc[df[\"region\"].isin(target_regions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b3a17-d49a-4052-a2ff-803b0024d9fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_cells_fiordland = [\n",
    "    \"-44.22428_167.67783\",\n",
    "    \"-44.74854_167.24373\",\n",
    "    \"-44.652485_167.81955\",\n",
    "    \"-45.271618_166.80473\",\n",
    "    \"-45.177055_167.38486\",\n",
    "    \"-45.08052_167.96336\",\n",
    "    \"-45.793488_166.36075\",\n",
    "    \"-45.70044_166.9453\",\n",
    "    \"-45.605396_167.52815\",\n",
    "    \"-46.222622_166.50067\",\n",
    "    \"-46.129093_167.08798\",\n",
    "    \"-46.033554_167.67365\",\n",
    "    \"-46.65158_166.64278\",\n",
    "    \"-46.557556_167.23296\",\n",
    "    \"-46.46152_167.82141\",\n",
    "]\n",
    "\n",
    "df.loc[df[\"grid_cell\"].isin(grid_cells_fiordland), \"region\"] = \"Fiordland Region\"\n",
    "df.loc[df[\"grid_cell\"].isin(grid_cells_fiordland), \"region\"] = \"Fiordland Region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58ee8c3-5f53-4ddb-bc76-a2ccd295a0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875fcaa-7b9f-48fa-8c27-7e9086deffcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def determine_quantiles_for_data(df_ALL, df_HOT, num_quantiles=100):\n",
    "    dfs = []\n",
    "\n",
    "    # Iterate over each grid cell\n",
    "    for grid_cell in tqdm(df_ALL[\"grid_cell\"].unique(), desc=\"Grid_cell Loop\"):\n",
    "        # Filter to that grid cell data\n",
    "        df_temp_ALL = df_ALL.loc[df_ALL[\"grid_cell\"] == grid_cell].copy()\n",
    "        df_temp_HOT = df_HOT.loc[df_HOT[\"grid_cell\"] == grid_cell].copy()\n",
    "\n",
    "        # Determine wet and dry quantiles\n",
    "        df_temp_ALL[\"wet_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_ALL[\"dry_quantile\"] = pd.qcut(df_temp_ALL[\"total_precip_dry_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"wet_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_wet_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "        df_temp_HOT[\"dry_quantile\"] = pd.qcut(df_temp_HOT[\"total_precip_dry_days\"], q=num_quantiles, labels=np.arange(1, num_quantiles + 1, 1))\n",
    "\n",
    "        # Change the quantile cols to strings then integers as they start as objects\n",
    "        df_temp_ALL[\"wet_quantile\"] = df_temp_ALL[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_ALL[\"dry_quantile\"] = df_temp_ALL[\"dry_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"wet_quantile\"] = df_temp_HOT[\"wet_quantile\"].astype(str).astype(int)\n",
    "        df_temp_HOT[\"dry_quantile\"] = df_temp_HOT[\"dry_quantile\"].astype(str).astype(int)\n",
    "\n",
    "        # ==================================================================================================================================\n",
    "        # I am quite tired and seem to have broken the \"merge\" function. I can't be bothered fixing it so this is a fast workaround\n",
    "\n",
    "        # Group by the quantiles taking the median of each quantile, this \"bins them\"\n",
    "        group_cols = [\n",
    "            \"grid_cell\",\n",
    "            \"days_wet\",\n",
    "            \"days_dry\",\n",
    "        ]\n",
    "        wet_cols = [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"wet_quantile\",\n",
    "        ]\n",
    "        dry_cols = [\n",
    "            \"total_precip_dry_days\",\n",
    "            \"dry_quantile\"\n",
    "        ]\n",
    "        df_ALL_wet = df_temp_ALL[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_ALL_dry = df_temp_ALL[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "        df_ALL_wet[\"total_precip_dry_days\"] = df_ALL_dry[\"total_precip_dry_days\"]\n",
    "        df_ALL_wet[\"dry_quantile\"] = df_ALL_dry[\"dry_quantile\"]\n",
    "        df_HOT_wet = df_temp_HOT[group_cols + [\"wet_quantile\", \"total_precip_wet_days\"]].groupby(by=group_cols + [\"wet_quantile\"]).median().reset_index().sort_values(\"wet_quantile\", ascending=True)\n",
    "        df_HOT_dry = df_temp_HOT[group_cols + [\"dry_quantile\", \"total_precip_dry_days\"]].groupby(by=group_cols + [\"dry_quantile\"]).median().reset_index().sort_values(\"dry_quantile\", ascending=True)\n",
    "        df_HOT_wet[\"total_precip_dry_days\"] = df_HOT_dry[\"total_precip_dry_days\"]\n",
    "        df_HOT_wet[\"dry_quantile\"] = df_HOT_dry[\"dry_quantile\"]\n",
    "\n",
    "        # Merge them back into one\n",
    "        df_merged = df_ALL_wet[group_cols]\n",
    "        for col in [\n",
    "            \"total_precip_wet_days\",\n",
    "            \"total_precip_dry_days\",\n",
    "            \"wet_quantile\",\n",
    "            \"dry_quantile\",\n",
    "        ]:\n",
    "            if \"wet\" in col:\n",
    "                df_merged[f\"{col}_HOT\"] = df_HOT_wet[col]\n",
    "                df_merged[f\"{col}_ALL\"] = df_ALL_wet[col]\n",
    "            else:\n",
    "                df_merged[f\"{col}_HOT\"] = df_HOT_dry[col]\n",
    "                df_merged[f\"{col}_ALL\"] = df_ALL_dry[col]\n",
    "\n",
    "        # ==================================================================================================================================\n",
    "\n",
    "        # Determine total_precip_xxx_days_fraction here to save time\n",
    "        df_merged[\"total_precip_wet_days_fraction\"] = (df_merged[\"total_precip_wet_days_HOT\"] / df_merged[\"total_precip_wet_days_ALL\"]).astype(float).round(3)\n",
    "        df_merged[\"total_precip_dry_days_fraction\"] = (df_merged[\"total_precip_dry_days_HOT\"] / df_merged[\"total_precip_dry_days_ALL\"]).astype(float).round(3)\n",
    "        \n",
    "        \n",
    "        # Pull out the lon and lat values\n",
    "        grid_cell_parts = grid_cell.split(\"_\")\n",
    "        lat = float(grid_cell_parts[0])\n",
    "        lon = float(grid_cell_parts[1])\n",
    "        df_merged[\"longitude\"] = lon\n",
    "        df_merged[\"latitude\"] = lat\n",
    "\n",
    "        # Append this to the big list\n",
    "        dfs.append(df_merged)\n",
    "\n",
    "    # Concat all the dfs into one giga-one\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dea078-9783-4ca6-923f-5c750cbbf7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ALL = df.loc[df[\"source\"] == \"ALL\"].copy().reset_index(drop=True)\n",
    "df_HOT = df.loc[df[\"source\"] == \"HOT\"].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Attach days required to datasets\n",
    "with open(f\"{DIR_HAPPI}/RVI/fixed_precip_grid_cell_map.json\") as json_file:\n",
    "    fixed_precip_grid_cell_map = load(json_file)\n",
    "    \n",
    "fixed_precip_grid_cell_map_wet = {}\n",
    "fixed_precip_grid_cell_map_dry = {}\n",
    "\n",
    "for key, value in fixed_precip_grid_cell_map.items():\n",
    "    fixed_precip_grid_cell_map_wet[key] = int(value[\"wet\"])\n",
    "    fixed_precip_grid_cell_map_dry[key] = int(value[\"dry\"])\n",
    "\n",
    "df_ALL[\"days_wet\"] = df_ALL[\"grid_cell\"].map(fixed_precip_grid_cell_map_wet)\n",
    "df_ALL[\"days_dry\"] = df_ALL[\"grid_cell\"].map(fixed_precip_grid_cell_map_dry)\n",
    "df_HOT[\"days_wet\"] = df_HOT[\"grid_cell\"].map(fixed_precip_grid_cell_map_wet)\n",
    "df_HOT[\"days_dry\"] = df_HOT[\"grid_cell\"].map(fixed_precip_grid_cell_map_dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc735c1-76e0-4557-b601-6f9f2fa91efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df5879-7605-4dd6-a428-a3ec12b822e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12df18b-1e8d-4dea-a924-130f17d81712",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The line plots comparing ensemble members against each other in the grid_cell (HOT / ALL for wet and dry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197462e-b719-4a4b-99b9-1e6c8f2c1a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_figures = dict()\n",
    "\n",
    "df_merged = pd.DataFrame()\n",
    "\n",
    "for region in target_regions + [\"Fiordland Region\"]:\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df_region_ALL = df_ALL.loc[df_ALL[\"region\"] == region]\n",
    "    df_region_HOT = df_HOT.loc[df_HOT[\"region\"] == region]\n",
    "    \n",
    "    df_region_merged = determine_quantiles_for_data(df_region_ALL, df_region_HOT, 100)\n",
    "    df_region_merged.rename(\n",
    "        columns={\n",
    "            \"total_precip_wet_days_fraction\": \"Wet End\", \n",
    "            \"total_precip_dry_days_fraction\": \"Dry End\",\n",
    "            \"wet_quantile_ALL\": \"Ranked Bin\"\n",
    "        }, \n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    df_region_merged[\"region\"] = region\n",
    "    \n",
    "    df_merged = pd.concat([df_merged, df_region_merged]).reset_index(drop=True)\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_region_merged,\n",
    "        x=\"Ranked Bin\",\n",
    "        y=[\"Wet End\", \"Dry End\"],\n",
    "        template=\"plotly_white\",\n",
    "        color_discrete_sequence=px.colors.qualitative.Bold[:]\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Comparing Expected Precipitation Volume HOT / ALL | {region}\",\n",
    "        height=600,\n",
    "        width=1000,\n",
    "        yaxis_range=[0.75, 1.25],\n",
    "        legend_title_text=\"\",\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"top\",\n",
    "            y=0.95,\n",
    "            xanchor=\"left\",\n",
    "            x=0.05\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title=\"Ranked Bin (splitting each quartile into 100 further bins)\")\n",
    "    fig.update_yaxes(title=\"Change in Expected Precipitation (relative scale)\")\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    fig.write_image(f\"../Plots_Thesis/LineComparison_{region.replace(' ', '')}.png\", scale=2)\n",
    "    \n",
    "    region_figures[region] = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e25314-2049-4c96-a568-ea2fcf945712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4a477-766b-415c-88ca-3122bb0a4685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdf9336c-5fff-4bb3-bb5e-7a6627a0e359",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc1190-9337-4d72-98cf-70a467a1afcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "for region in target_regions + [\"Fiordland Region\"]:\n",
    "    \n",
    "    df_region = df.loc[df[\"region\"] == region].copy()\n",
    "    grid_cells = df_region[\"grid_cell\"].unique()\n",
    "    num_grid_cells = len(grid_cells)\n",
    "    print(f\"For {region} - found {num_grid_cells} grid cells\")\n",
    "    \n",
    "    for theme in [\"dry\", \"wet\"]:\n",
    "    \n",
    "        fig = make_subplots(\n",
    "            cols=3, \n",
    "            rows=math.ceil(num_grid_cells / 3),\n",
    "            subplot_titles=tuple(grid_cells)\n",
    "        )\n",
    "        row = 1\n",
    "        col = 1\n",
    "        \n",
    "        for grid_cell in grid_cells:\n",
    "            \n",
    "            df_cell = df_region.loc[df_region[\"grid_cell\"] == grid_cell]\n",
    "            \n",
    "            values_ALL = df_cell.loc[df_cell[\"source\"] == \"ALL\"][f\"total_precip_{theme}_days\"]\n",
    "            values_HOT = df_cell.loc[df_cell[\"source\"] == \"HOT\"][f\"total_precip_{theme}_days\"]\n",
    "            opacity = 0.6\n",
    "            num_bins = 150\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=values_ALL, \n",
    "                    # xbins={\"start\": 0, \"end\": values_ALL.max(), \"size\":10},\n",
    "                    nbinsx=num_bins,\n",
    "                    opacity=opacity,\n",
    "                    marker_color=\"blue\",\n",
    "                    name=\"ALL\"\n",
    "                ),\n",
    "                col=col,\n",
    "                row=row\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=values_HOT, \n",
    "                    # xbins={\"start\": 0, \"end\": values_HOT.max(), \"size\":10},\n",
    "                    nbinsx=num_bins,\n",
    "                    opacity=opacity,\n",
    "                    marker_color=\"red\",\n",
    "                    name=\"HOT\"\n",
    "                ),\n",
    "                col=col,\n",
    "                row=row\n",
    "            )\n",
    "            \n",
    "            col += 1\n",
    "            if col == 4:\n",
    "                col = 1\n",
    "                row += 1\n",
    "\n",
    "        fig.update_traces(marker_line_width=0.5,marker_line_color=\"black\")\n",
    "        \n",
    "        if region == \"Tasman Region\":\n",
    "            height = num_grid_cells * 120\n",
    "        else:\n",
    "            height = num_grid_cells * 80\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f\"{region} - Ensemble members 25% annual precipitation volume histograms for {theme} end\",\n",
    "            height=height,\n",
    "            width=1000,\n",
    "            showlegend=False,\n",
    "            barmode=\"overlay\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "\n",
    "        fig.update_yaxes(title_text=\"\")\n",
    "        fig.update_xaxes(title_text=\"\")\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        fig.write_image(f\"../Plots_Thesis/Histograms_{region.replace(' ', '')}_{theme}.png\", scale=2)\n",
    "        \n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b6869-9fb3-4e06-b78f-7a322e982b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf2ff9-4f43-4c62-9984-efdae2d468fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e134289f-23bf-4549-9091-ebaccb288fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "515c4f9f-d260-467b-bb30-f27d4f179730",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Determine stats for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2e9d3-228d-4f14-8259-e0b1643b6bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chosen_region = \"Southland Region\"\n",
    "\n",
    "df_temp_ALL = df_ALL.loc[df_ALL[\"region\"] == chosen_region]\n",
    "df_temp_HOT = df_HOT.loc[df_HOT[\"region\"] == chosen_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1c915-4c88-4acf-8f03-cc68b96479e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ee9b7-14e7-413c-a391-274733ce9458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c36c1-3cfd-494f-a350-aac9242b8a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam.plot(df_temp_ALL, \"total_precip_dry_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4f7ca-dc24-4e11-bae8-32b7ec18edea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam.plot(df_temp_ALL, \"total_precip_wet_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f7b40-b5dc-4dc0-90ce-90ae623b6b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb3657-a461-412a-9aaa-4fe9b309f363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589297a7-c596-4d45-bd22-3e89bd22a575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam.plot(df_temp_HOT, \"total_precip_dry_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f30a7-5f2e-4c00-9a99-72c0a5699bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam.plot(df_temp_HOT, \"total_precip_wet_days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21246a94-a30a-4682-b825-c466b49d1e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6ab29-2e98-42a2-a2a3-aee0d15a3b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam.plot(df_temp_ALL, 'days_wet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f7398-7f61-48bc-a349-7eb4a8d7bc28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bam.plot(df_temp_ALL, 'days_dry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc298b7-3954-41cf-8451-70809a29cdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e1080a7-a728-4a73-8d3f-8363469f8d0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Single ensemble member rainfall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde9fe8-acbb-4764-b5ba-bfa0bca6d967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_line(fig, x_val, y_val, colour, name):\n",
    "    fig.add_shape(\n",
    "        type='line', \n",
    "        x0=x_val, \n",
    "        x1=x_val, \n",
    "        y0=0, \n",
    "        y1=y_val, \n",
    "        opacity=0.85,\n",
    "        line=dict(color=colour, width=3, dash='dash'),\n",
    "        xref='x', \n",
    "        yref='y', \n",
    "        layer='above',\n",
    "        name=name,\n",
    "        showlegend=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dfb2b-43bb-41d5-9be0-5d1a6809be51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76032f90-d78e-43d8-a537-27ecb7ce0d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_single = pd.read_parquet(f\"{DIR_HAPPI}/Processed/year=2010/region=Northland Region/sim=ALL/model_tag=a0t6/\")\n",
    "df_single = df_single.loc[df_single[\"grid_cell\"] == \"-34.648323_172.58727\"]\n",
    "df_single = df_single.sort_values(by=[\"precip_mm\"], ascending=False).reset_index(drop=True)\n",
    "# df_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e2b1bc-fb8e-4e35-a0a0-9458c59ba4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        y=df_single[\"precip_mm\"], \n",
    "        opacity=0.6,\n",
    "        marker_color=\"green\",\n",
    "        name=\"Daily Precipitation\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(marker_line_width=0.5,marker_line_color=\"black\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Single ensemble member precipitation | Grid Cell -34.648323_172.58727 | Model a0t6 | 2010\",\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    showlegend=True,\n",
    "    barmode=\"overlay\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.90,\n",
    "        xanchor=\"left\",\n",
    "        x=0.75\n",
    "    )\n",
    ")\n",
    "\n",
    "add_line(fig, 5, 70, \"blue\", \"Wet Days Cutoff\")\n",
    "add_line(fig, 42, 70, \"red\", \"Dry Days Cutoff\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Daily Precipitation (mm)\")\n",
    "fig.update_xaxes(title_text=\"Ranked Days\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc38937-6aba-4dad-9377-e4d2ab9b9126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig.write_image(f\"../Plots_Thesis/RankedPrecipitation_NorthlandRegion.png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868d1e6-658d-4ce2-8ff9-7d877f87774f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea884ca5-76d5-495b-af83-c8e46723f39d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Country wide change plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514d803-1329-42f7-9f41-59fa4a44d40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_difference_map_quantile(df_merged, target_quantile, target_scenario):\n",
    "    colour_map = {\n",
    "        \"Dry End\": \"OrRd\",\n",
    "        \"Wet End\": \"GnBu\"\n",
    "    }\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_merged, \n",
    "        x='longitude', \n",
    "        y='latitude', \n",
    "        color=f\"{target_scenario}\", \n",
    "        symbol_sequence=[\"circle\"], \n",
    "        height=900, \n",
    "        width=800,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_map[target_scenario],\n",
    "        range_color=(0.75, 1.25)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Change in Expected Precipitation (HOT / ALL) {target_scenario} [ {target_quantile}th bin ]\",\n",
    "        coloraxis_colorbar=dict(title=\"\")\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title=\"Longitude\", visible=True)\n",
    "    fig.update_yaxes(title=\"Latitude\", visible=True)\n",
    "    \n",
    "    fig.update_traces(marker={'size': 21})\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738e842-8235-4719-811b-4d4eb5eae637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f384a416-51d3-4073-8986-62c24bea2ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged = determine_quantiles_for_data(df_ALL, df_HOT, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f9361d-44dc-4f6d-bcfc-c0e11d69df8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_merged.rename(\n",
    "    columns={\n",
    "        \"total_precip_wet_days_fraction\": \"Wet End\", \n",
    "        \"total_precip_dry_days_fraction\": \"Dry End\"\n",
    "    }, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d251a35-967a-453d-a641-afaadf330281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681ff7e-3d75-4b18-9069-38ca64d3c2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for target_quantile in [10]:\n",
    "    df_quantile = df_merged.loc[df_merged[\"dry_quantile_ALL\"] == target_quantile].copy()\n",
    "\n",
    "    fig_wet = plot_difference_map_quantile(df_quantile, target_quantile, \"Wet End\")\n",
    "    fig_dry = plot_difference_map_quantile(df_quantile, target_quantile, \"Dry End\")\n",
    "\n",
    "    fig_wet.show()\n",
    "    fig_dry.show()\n",
    "\n",
    "#     fig_wet.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.html\")\n",
    "#     fig_dry.write_html(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.html\")\n",
    "\n",
    "#     fig_wet.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_wet.png\", format=\"png\", scale=2)\n",
    "#     fig_dry.write_image(f\"{DIR_PLOTS}/NZ_change_{target_quantile}th_quantile_dry.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ce932-ed5e-43a8-83b5-8ed5e1b40ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_quantile = df_quantile.set_geometry(\n",
    "    geopandas.points_from_xy(\n",
    "        x=df_quantile[\"longitude\"],\n",
    "        y=df_quantile[\"latitude\"],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df_quantile.explore(\"Dry End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c83a78-e915-4e49-b795-2e6e9dfd1fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb1b7c-d02a-475a-8e82-8cbf68f44422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2d1fb7-7eef-4962-b07c-94f845e27e99",
   "metadata": {},
   "source": [
    "# Review Requests - Days taken to reach 25% for all grid-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2ce1e-d923-4a64-b591-a15d2bdfb714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51693343-eba1-4c46-9299-18cb6dae4048",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## For paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924d7ef-43af-41c7-9d6c-4ae1a3e02ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"region\",\n",
    "    \"grid_cell\",\n",
    "]\n",
    "\n",
    "df_wah = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_PrecipPercent\")\n",
    "df_wah = df_wah.loc[df_wah[\"source\"] == \"ALL\"].reset_index(drop=True)\n",
    "\n",
    "df_wah_grouped = df_wah[group_cols + [\"wet\", \"dry\"]].groupby(group_cols).agg({\"wet\": \"median\", \"dry\": \"median\"}).reset_index(drop=False)\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_wah_grouped['grid_cell'].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"lat\", \"lon\"]\n",
    "split_df[\"lat\"] = split_df[\"lat\"].astype(float)\n",
    "split_df[\"lon\"] = split_df[\"lon\"].astype(float)\n",
    "df_wah_grouped = pd.merge(df_wah_grouped, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "df_wah_grouped[\"wet\"] = np.floor(df_wah_grouped[\"wet\"])\n",
    "df_wah_grouped[\"dry\"] = np.floor(df_wah_grouped[\"dry\"])\n",
    "\n",
    "\n",
    "\n",
    "df_vcsn = pd.read_parquet(f\"{DIR_VCSN}/RVI/Chunks_Fixed_PrecipPercent/\")\n",
    "df_vcsn = df_vcsn.loc[df_vcsn[\"year\"].astype(int).between(2007, 2016)]\n",
    "\n",
    "df_vcsn_grouped = df_vcsn[group_cols + [\"wet\", \"dry\"]].groupby(group_cols).agg({\"wet\": \"median\", \"dry\": \"median\"}).reset_index(drop=False)\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_vcsn_grouped['grid_cell'].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"lat\", \"lon\"]\n",
    "split_df[\"lat\"] = split_df[\"lat\"].astype(float)\n",
    "split_df[\"lon\"] = split_df[\"lon\"].astype(float)\n",
    "df_vcsn_grouped = pd.merge(df_vcsn_grouped, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "df_vcsn_grouped[\"wet\"] = np.floor(df_vcsn_grouped[\"wet\"])\n",
    "df_vcsn_grouped[\"dry\"] = np.floor(df_vcsn_grouped[\"dry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91bbe8e-8580-4964-9a77-3c86b28c6062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7edaca-e109-404b-9ae1-0a1d37214584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef10e24-50ea-4e54-a9f3-672926d51d79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colour_map_wet = {\n",
    "    \"wet_0\": \"rgb(0.478431373, 0.003921569, 0.466666667)\",\n",
    "    \"wet_1\": \"rgb(0.682352941, 0.003921569, 0.494117647)\",\n",
    "    \"wet_2\": \"rgb(0.866666667, 0.203921569, 0.592156863)\",\n",
    "    \"wet_3\": \"rgb(0.968627451, 0.407843137, 0.631372549)\",\n",
    "    \"wet_4\": \"rgb(0.980392157, 0.623529412, 0.709803922)\",\n",
    "    \"wet_5\": \"rgb(0.988235294, 0.772549020, 0.752941176)\",\n",
    "    \"wet_6\": \"rgb(0.996078431, 0.921568627, 0.886274510)\",\n",
    "}\n",
    "\n",
    "colour_map_dry = {\n",
    "    \"dry_0\": \"rgb(1.000000000, 1.000000000, 0.831372549)\",\n",
    "    \"dry_1\": \"rgb(0.996078431, 0.890196078, 0.568627451)\",\n",
    "    \"dry_2\": \"rgb(0.996078431, 0.768627451, 0.309803922)\",\n",
    "    \"dry_3\": \"rgb(0.996078431, 0.600000000, 0.160784314)\",\n",
    "    \"dry_4\": \"rgb(0.925490196, 0.439215686, 0.078431373)\",\n",
    "    \"dry_5\": \"rgb(0.800000000, 0.298039216, 0.007843137)\",\n",
    "    \"dry_6\": \"rgb(0.549019608, 0.176470588, 0.015686275)\",\n",
    "}\n",
    "\n",
    "colour_boundaries = {\n",
    "    \"VCSN\" : {\n",
    "        \"wet\": [\n",
    "            (0.000, colour_map_wet[\"wet_0\"]), (0.167, colour_map_wet[\"wet_0\"]),   \n",
    "            (0.167, colour_map_wet[\"wet_1\"]), (0.333, colour_map_wet[\"wet_1\"]),\n",
    "            (0.333, colour_map_wet[\"wet_2\"]), (0.500, colour_map_wet[\"wet_2\"]),\n",
    "            (0.500, colour_map_wet[\"wet_3\"]), (0.667, colour_map_wet[\"wet_3\"]),\n",
    "            (0.667, colour_map_wet[\"wet_4\"]), (0.833, colour_map_wet[\"wet_4\"]),\n",
    "            (0.833, colour_map_wet[\"wet_5\"]), (1.000, colour_map_wet[\"wet_5\"]),\n",
    "            (1.000, colour_map_wet[\"wet_6\"]), (1.000, colour_map_wet[\"wet_6\"]),\n",
    "        ],\n",
    "        \"dry\": [\n",
    "            (0.000, colour_map_dry[\"dry_0\"]), (0.045, colour_map_dry[\"dry_0\"]),\n",
    "            (0.045, colour_map_dry[\"dry_1\"]), (0.197, colour_map_dry[\"dry_1\"]),\n",
    "            (0.197, colour_map_dry[\"dry_2\"]), (0.348, colour_map_dry[\"dry_2\"]),\n",
    "            (0.348, colour_map_dry[\"dry_3\"]), (0.500, colour_map_dry[\"dry_3\"]),\n",
    "            (0.500, colour_map_dry[\"dry_4\"]), (0.652, colour_map_dry[\"dry_4\"]),\n",
    "            (0.652, colour_map_dry[\"dry_5\"]), (0.803, colour_map_dry[\"dry_5\"]),\n",
    "            (0.803, colour_map_dry[\"dry_6\"]), (1.000, colour_map_dry[\"dry_6\"]),\n",
    "        ]\n",
    "    },\n",
    "    \"WaH ALL\": {\n",
    "        \"wet\": [\n",
    "            (0.000, colour_map_wet[\"wet_0\"]), (0.100, colour_map_wet[\"wet_0\"]),\n",
    "            (0.100, colour_map_wet[\"wet_1\"]), (0.200, colour_map_wet[\"wet_1\"]),\n",
    "            (0.200, colour_map_wet[\"wet_2\"]), (0.300, colour_map_wet[\"wet_2\"]),\n",
    "            (0.300, colour_map_wet[\"wet_3\"]), (0.400, colour_map_wet[\"wet_3\"]),\n",
    "            (0.400, colour_map_wet[\"wet_4\"]), (0.500, colour_map_wet[\"wet_4\"]),\n",
    "            (0.500, colour_map_wet[\"wet_5\"]), (0.600, colour_map_wet[\"wet_5\"]),\n",
    "            (0.600, colour_map_wet[\"wet_6\"]), (1.000, colour_map_wet[\"wet_6\"]),\n",
    "        ],\n",
    "        \"dry\": [\n",
    "            \n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "colour_midpoints = {\n",
    "    \"wet\": 8,\n",
    "    \"dry\": 310\n",
    "}\n",
    "\n",
    "tick_vals = {\n",
    "    \"wet\": [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "    \"dry\": [270, 280, 290, 300, 310, 320, 330, 340, 350],\n",
    "}\n",
    "    \n",
    "tick_text = {\n",
    "    \"wet\": [\"2\", \"4\", \"6\", \"8\", \"10\", \"12\", \"14\", \"16+\"],\n",
    "    \"dry\": [\"270\", \"280\", \"290\", \"300\", \"310\", \"320\", \"330\", \"340+\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d01f7-1c83-41e8-a530-020175cb74be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_day_plot(df, feature, data_source):\n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x='lon', \n",
    "        y='lat', \n",
    "        height=950, \n",
    "        width=800, \n",
    "        color=feature,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_boundaries[data_source][feature],\n",
    "        color_continuous_midpoint=colour_midpoints[feature]\n",
    "    )\n",
    "    \n",
    "    amount_str = \"Fewest\" if feature == \"wet\" else \"Most\"\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"{amount_str} days needed to reach 25% of annual rainfall - {data_source}\",\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=\"\",\n",
    "            orientation=\"h\",\n",
    "            y=-0.2,\n",
    "            yanchor=\"bottom\",\n",
    "            ticks=\"outside\",\n",
    "            tickmode=\"array\",\n",
    "            tickvals=tick_vals[feature],\n",
    "            ticktext=tick_text[feature],\n",
    "            outlinecolor=\"rgb(0.0, 0.0, 0.0)\",\n",
    "            outlinewidth=1,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    dot_size = 5 if data_source == \"VCSN\" else 20\n",
    "\n",
    "    fig.update_traces(marker={\n",
    "        'size': dot_size,\n",
    "        \"symbol\": \"circle\"\n",
    "    })\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789c92b-4e62-4b4d-98f2-d73c0833f5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vcsn_wet_fig = build_day_plot(df_vcsn_grouped, \"wet\", \"VCSN\")\n",
    "vcsn_wet_fig.write_image(f\"{DIR_PLOTS}/VCSN_fewest_wet_days.png\", format=\"png\", scale=2)\n",
    "\n",
    "vcsn_dry_fig = build_day_plot(df_vcsn_grouped, \"dry\", \"VCSN\")\n",
    "vcsn_dry_fig.write_image(f\"{DIR_PLOTS}/VCSN_most_dry_days.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844f1de-c88f-4e80-b5bc-20f4553b480f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68213736-6572-4037-aed1-e6fb5df99d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature = \"dry\"\n",
    "nums = tick_vals[feature]\n",
    "\n",
    "val_max = df_vcsn_grouped[feature].max()\n",
    "print(f\"Max: {val_max}\")\n",
    "val_min = df_vcsn_grouped[feature].min()\n",
    "print(f\"Min: {val_min}\")\n",
    "print()\n",
    "\n",
    "for num in nums:\n",
    "    print(f\"{((num - val_min) / (val_max - val_min)):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde98420-5ce6-4095-a94b-30a6a3a0f89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a49f5-f30d-4da7-93a9-cc64632b47e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e7079-c9b8-42e8-a5f4-1f8b96f91130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7baf3f-f8f0-400e-aa83-f410d4a5fab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88cf921-2458-43de-b792-416638a1ee6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01d3db-e6e3-45f3-a998-b85e22aad54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1fec2-c7a3-4aa6-a68c-cb2790e94aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28a814ec-72c9-433a-84a2-16fff6d26d60",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For thesis - median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee826e-691a-4612-a16f-ddce27c95720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0fc10-0c8d-4173-bddf-3091100a597f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"region\",\n",
    "    \"grid_cell\",\n",
    "]\n",
    "\n",
    "df_wah = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_PrecipPercent\")\n",
    "df_wah = df_wah.loc[df_wah[\"source\"] == \"ALL\"].reset_index(drop=True)\n",
    "\n",
    "df_wah_grouped = df_wah[group_cols + [\"wet\", \"dry\"]].groupby(group_cols).agg({\"wet\": \"median\", \"dry\": \"median\"}).reset_index(drop=False)\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_wah_grouped['grid_cell'].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"lat\", \"lon\"]\n",
    "split_df[\"lat\"] = split_df[\"lat\"].astype(float)\n",
    "split_df[\"lon\"] = split_df[\"lon\"].astype(float)\n",
    "df_wah_grouped = pd.merge(df_wah_grouped, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "df_wah_grouped[\"wet\"] = np.floor(df_wah_grouped[\"wet\"])\n",
    "df_wah_grouped[\"dry\"] = np.floor(df_wah_grouped[\"dry\"])\n",
    "\n",
    "\n",
    "\n",
    "df_vcsn = pd.read_parquet(f\"{DIR_VCSN}/RVI/Chunks_Fixed_PrecipPercent/\")\n",
    "df_vcsn = df_vcsn.loc[df_vcsn[\"year\"].astype(int).between(2007, 2016)]\n",
    "\n",
    "df_vcsn_grouped = df_vcsn[group_cols + [\"wet\", \"dry\"]].groupby(group_cols).agg({\"wet\": \"median\", \"dry\": \"median\"}).reset_index(drop=False)\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_vcsn_grouped['grid_cell'].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"lat\", \"lon\"]\n",
    "split_df[\"lat\"] = split_df[\"lat\"].astype(float)\n",
    "split_df[\"lon\"] = split_df[\"lon\"].astype(float)\n",
    "df_vcsn_grouped = pd.merge(df_vcsn_grouped, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "df_vcsn_grouped[\"wet\"] = np.floor(df_vcsn_grouped[\"wet\"])\n",
    "df_vcsn_grouped[\"dry\"] = np.floor(df_vcsn_grouped[\"dry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744ff5b-cae3-477d-b9b6-36acc99cd0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c497b0b-0548-426e-aeac-170e780d1979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c307d1-e4cb-4f05-a2c2-9df493971746",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_day_plot(df, feature, data_source):\n",
    "    colour_range = {\n",
    "        \"wet\": (2, 14),\n",
    "        \"dry\": (270, 340)\n",
    "    }\n",
    "    \n",
    "    colour_scale = {\n",
    "        \"wet\": \"agsunset\",\n",
    "        \"dry\": \"oranges\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x='lon', \n",
    "        y='lat', \n",
    "        height=950, \n",
    "        width=800, \n",
    "        color=feature,\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_scale[feature],\n",
    "        range_color=colour_range[feature]\n",
    "    )\n",
    "    \n",
    "    amount_str = \"Fewest\" if feature == \"wet\" else \"Most\"\n",
    "    d_ticks = 2 if feature == \"wet\" else 10\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"{amount_str} days needed to reach 25% of annual rainfall - {data_source}\",\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=\"\",\n",
    "            orientation=\"h\",\n",
    "            y=-0.2,\n",
    "            yanchor=\"bottom\",\n",
    "            dtick=d_ticks,\n",
    "            ticks=\"outside\",\n",
    "            outlinecolor=\"rgb(0.0, 0.0, 0.0)\",\n",
    "            outlinewidth=1,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    dot_size = 5 if data_source == \"VCSN\" else 20\n",
    "\n",
    "    fig.update_traces(marker={\n",
    "        'size': dot_size,\n",
    "        \"symbol\": \"circle\"\n",
    "    })\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90618dcd-2cca-4ad1-8cda-ca8e72ba57e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11370df6-8c61-4e23-a2a0-774a93494cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_vcsn_wet = build_day_plot(df_vcsn_grouped, \"wet\", \"VCSN\")\n",
    "fig_vcsn_wet.write_image(f\"{DIR_PLOTS_THESIS}/VCSN_fewest_wet_days.png\", format=\"png\", scale=2)\n",
    "\n",
    "fig_vcsn_dry = build_day_plot(df_vcsn_grouped, \"dry\", \"VCSN\")\n",
    "fig_vcsn_dry.write_image(f\"{DIR_PLOTS_THESIS}/VCSN_most_dry_days.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9a21a-f4f6-456a-a92b-97b5f9a106a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b631f6-5935-4c7c-bd39-debefb8c2ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_wah_wet = build_day_plot(df_wah_grouped, \"wet\", \"WaH ALL\")\n",
    "fig_wah_wet.write_image(f\"{DIR_PLOTS_THESIS}/WaH_fewest_wet_days.png\", format=\"png\", scale=2)\n",
    "\n",
    "fig_wah_dry = build_day_plot(df_wah_grouped, \"dry\", \"WaH ALL\")\n",
    "fig_wah_dry.write_image(f\"{DIR_PLOTS_THESIS}/WaH_most_dry_days.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17272c0c-45c6-4650-82e6-a286e37da232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d80441b-7568-49d2-ba92-05483a55b6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "261eb39b-a2f6-4431-b71c-1dcda75a84e9",
   "metadata": {},
   "source": [
    "## For Thesis - Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03458c45-5032-4845-9afc-9d5a824a1f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_cols = [\n",
    "    \"region\",\n",
    "    \"grid_cell\",\n",
    "]\n",
    "\n",
    "df_wah = pd.read_parquet(f\"{DIR_HAPPI}/RVI/Chunks_Fixed_PrecipPercent\")\n",
    "df_wah = df_wah.loc[df_wah[\"source\"] == \"ALL\"].reset_index(drop=True)\n",
    "\n",
    "df_wah_grouped = df_wah[group_cols + [\"wet\", \"dry\"]].groupby(group_cols).agg({\"wet\": [\"median\", \"max\", \"min\"], \"dry\": [\"median\", \"max\", \"min\"]}).reset_index(drop=False)\n",
    "df_wah_grouped.columns = [\"region\", \"grid_cell\", \"wet_median\", \"wet_max\", \"wet_min\", \"dry_median\", \"dry_max\", \"dry_min\"]\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_wah_grouped['grid_cell'].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"lat\", \"lon\"]\n",
    "split_df[\"lat\"] = split_df[\"lat\"].astype(float)\n",
    "split_df[\"lon\"] = split_df[\"lon\"].astype(float)\n",
    "df_wah_grouped = pd.merge(df_wah_grouped, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "df_wah_grouped[\"wet_median\"] = np.floor(df_wah_grouped[\"wet_median\"])\n",
    "df_wah_grouped[\"dry_median\"] = np.floor(df_wah_grouped[\"dry_median\"])\n",
    "df_wah_grouped[\"wet_range\"] = df_wah_grouped[\"wet_max\"] - df_wah_grouped[\"wet_min\"]\n",
    "df_wah_grouped[\"dry_range\"] = df_wah_grouped[\"dry_max\"] - df_wah_grouped[\"dry_min\"]\n",
    "\n",
    "\n",
    "\n",
    "df_vcsn = pd.read_parquet(f\"{DIR_VCSN}/RVI/Chunks_Fixed_PrecipPercent/\")\n",
    "df_vcsn = df_vcsn.loc[df_vcsn[\"year\"].astype(int).between(2007, 2016)]\n",
    "\n",
    "df_vcsn_grouped = df_vcsn[group_cols + [\"wet\", \"dry\"]].groupby(group_cols).agg({\"wet\": [\"median\", \"max\", \"min\"], \"dry\": [\"median\", \"max\", \"min\"]}).reset_index(drop=False)\n",
    "df_vcsn_grouped.columns = [\"region\", \"grid_cell\", \"wet_median\", \"wet_max\", \"wet_min\", \"dry_median\", \"dry_max\", \"dry_min\"]\n",
    "\n",
    "# Step: Manipulate strings of 'grid_cell' and perform a split on '_'\n",
    "split_df = df_vcsn_grouped['grid_cell'].str.split('_', n=2, expand=True)\n",
    "split_df.columns = [\"lat\", \"lon\"]\n",
    "split_df[\"lat\"] = split_df[\"lat\"].astype(float)\n",
    "split_df[\"lon\"] = split_df[\"lon\"].astype(float)\n",
    "df_vcsn_grouped = pd.merge(df_vcsn_grouped, split_df, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "df_vcsn_grouped[\"wet_median\"] = np.floor(df_vcsn_grouped[\"wet_median\"])\n",
    "df_vcsn_grouped[\"dry_median\"] = np.floor(df_vcsn_grouped[\"dry_median\"])\n",
    "df_vcsn_grouped[\"wet_range\"] = df_vcsn_grouped[\"wet_max\"] - df_vcsn_grouped[\"wet_min\"]\n",
    "df_vcsn_grouped[\"dry_range\"] = df_vcsn_grouped[\"dry_max\"] - df_vcsn_grouped[\"dry_min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04284c08-1aa3-4111-af66-40c6cf003ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018998ed-2787-4b0a-9e2b-982cffc27a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_day_plot(df, feature, data_source):\n",
    "    colour_range = {\n",
    "        \"wet\": (0, 14),\n",
    "        \"dry\": (0, 50)\n",
    "    }\n",
    "    \n",
    "    colour_scale = {\n",
    "        \"wet\": \"agsunset\",\n",
    "        \"dry\": \"oranges\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x='lon', \n",
    "        y='lat', \n",
    "        height=950, \n",
    "        width=800, \n",
    "        color=f\"{feature}_range\",\n",
    "        template=\"plotly_white\",\n",
    "        color_continuous_scale=colour_scale[feature],\n",
    "        range_color=colour_range[feature]\n",
    "    )\n",
    "    \n",
    "    d_ticks = 2 if feature == \"wet\" else 10\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f\"Range of {feature} days needed to reach 25% of annual rainfall - {data_source}\",\n",
    "        coloraxis_colorbar=dict(\n",
    "            title=\"\",\n",
    "            orientation=\"h\",\n",
    "            y=-0.2,\n",
    "            yanchor=\"bottom\",\n",
    "            dtick=d_ticks,\n",
    "            ticks=\"outside\",\n",
    "            outlinecolor=\"rgb(0.0, 0.0, 0.0)\",\n",
    "            outlinewidth=1,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    dot_size = 5 if data_source == \"VCSN\" else 20\n",
    "\n",
    "    fig.update_traces(marker={\n",
    "        'size': dot_size,\n",
    "        \"symbol\": \"circle\"\n",
    "    })\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c90e83-c490-4248-80aa-a27b1de9c47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b505671-d49e-41a3-b894-280b1186aae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_vcsn_wet = build_day_plot(df_vcsn_grouped, \"wet\", \"VCSN\")\n",
    "fig_vcsn_wet.write_image(f\"{DIR_PLOTS_THESIS}/VCSN_range_wet_days.png\", format=\"png\", scale=2)\n",
    "\n",
    "fig_vcsn_dry = build_day_plot(df_vcsn_grouped, \"dry\", \"VCSN\")\n",
    "fig_vcsn_dry.write_image(f\"{DIR_PLOTS_THESIS}/VCSN_range_dry_days.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24af20-32cf-415f-8d15-29a59eec1bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944d8af-b53f-432a-b146-d5a5a29f03e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig_wah_wet = build_day_plot(df_wah_grouped, \"wet\", \"WaH ALL\")\n",
    "fig_wah_wet.write_image(f\"{DIR_PLOTS_THESIS}/WaH_range_wet_days.png\", format=\"png\", scale=2)\n",
    "\n",
    "fig_wah_dry = build_day_plot(df_wah_grouped, \"dry\", \"WaH ALL\")\n",
    "fig_wah_dry.write_image(f\"{DIR_PLOTS_THESIS}/WaH_range_dry_days.png\", format=\"png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629ffe4-7ebe-44c6-b44e-6315266c5194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b2e68-f89d-4c9c-a5b4-8cf84584d704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8308d77d-3cc8-402a-bc6e-929bb8d06a2a",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fde095-1ddf-41ee-9e2f-d9237cbe4cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6fc66-1b40-459a-93d6-18ea8dc456bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
